{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T04:16:54.569748Z",
     "iopub.status.busy": "2022-12-02T04:16:54.569385Z",
     "iopub.status.idle": "2022-12-02T04:17:03.975780Z",
     "shell.execute_reply": "2022-12-02T04:17:03.974408Z",
     "shell.execute_reply.started": "2022-12-02T04:16:54.569717Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All modules have been imported\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#import cv2\n",
    "#import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "#import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import scipy\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "from keras import preprocessing\n",
    "\n",
    "from tensorflow.keras.applications import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.losses import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras.preprocessing.image import *\n",
    "from tensorflow.keras.utils import *\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import *\n",
    "import tensorflow.keras.backend as K\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from colorama import Fore\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from skimage.io import *\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from keras.layers import Input\n",
    "from keras import layers\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import GlobalMaxPooling2D\n",
    "from keras.layers import ZeroPadding2D\n",
    "from keras.layers import AveragePooling2D\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Softmax\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "#from keras.preprocessing import image\n",
    "\n",
    "import keras.backend as K\n",
    "import keras_applications\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import decode_predictions\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras_applications.imagenet_utils import _obtain_input_shape\n",
    "from keras.utils.layer_utils import get_source_inputs\n",
    "print(\"All modules have been imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T04:17:03.978937Z",
     "iopub.status.busy": "2022-12-02T04:17:03.978512Z",
     "iopub.status.idle": "2022-12-02T04:17:03.984358Z",
     "shell.execute_reply": "2022-12-02T04:17:03.983376Z",
     "shell.execute_reply.started": "2022-12-02T04:17:03.978890Z"
    }
   },
   "outputs": [],
   "source": [
    "scale_percent = 100 # percent of original size\n",
    "width = int(np.round(600 * scale_percent / 100))\n",
    "height = int(np.round(300 * scale_percent / 100))\n",
    "dim = (width, height)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###############################<br>\n",
    "# ResNet50 Model Definition ###<br>\n",
    "###############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T04:17:03.986716Z",
     "iopub.status.busy": "2022-12-02T04:17:03.986008Z",
     "iopub.status.idle": "2022-12-02T04:17:04.007481Z",
     "shell.execute_reply": "2022-12-02T04:17:04.006401Z",
     "shell.execute_reply.started": "2022-12-02T04:17:03.986680Z"
    }
   },
   "outputs": [],
   "source": [
    "WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels.h5'\n",
    "WEIGHTS_PATH_NO_TOP = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T04:17:04.011100Z",
     "iopub.status.busy": "2022-12-02T04:17:04.010289Z",
     "iopub.status.idle": "2022-12-02T04:17:04.020822Z",
     "shell.execute_reply": "2022-12-02T04:17:04.019872Z",
     "shell.execute_reply.started": "2022-12-02T04:17:04.011066Z"
    }
   },
   "outputs": [],
   "source": [
    "def identity_block(input_tensor, kernel_size, filters, stage, block):\n",
    "    \"\"\"The identity block is the block that has no conv layer at shortcut.\n",
    "    # Arguments\n",
    "        input_tensor: input tensor\n",
    "        kernel_size: defualt 3, the kernel size of middle conv layer at main path\n",
    "        filters: list of integers, the filterss of 3 conv layer at main path\n",
    "        stage: integer, current stage label, used for generating layer names\n",
    "        block: 'a','b'..., current block label, used for generating layer names\n",
    "    # Returns\n",
    "        Output tensor for the block.\n",
    "    \"\"\"\n",
    "    filters1, filters2, filters3 = filters\n",
    "    if K.image_data_format() == 'channels_last':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    x = Conv2D(filters1, (1, 1), name=conv_name_base + '2a')(input_tensor)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(filters2, kernel_size,\n",
    "               padding='same', name=conv_name_base + '2b')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(filters3, (1, 1), name=conv_name_base + '2c')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
    "    x = layers.add([x, input_tensor])\n",
    "    x = Activation('relu')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T04:17:04.022762Z",
     "iopub.status.busy": "2022-12-02T04:17:04.022334Z",
     "iopub.status.idle": "2022-12-02T04:17:04.034483Z",
     "shell.execute_reply": "2022-12-02T04:17:04.033491Z",
     "shell.execute_reply.started": "2022-12-02T04:17:04.022728Z"
    }
   },
   "outputs": [],
   "source": [
    "def conv_block(input_tensor, kernel_size, filters, stage, block, strides=(2, 2)):\n",
    "    \"\"\"conv_block is the block that has a conv layer at shortcut\n",
    "    # Arguments\n",
    "        input_tensor: input tensor\n",
    "        kernel_size: defualt 3, the kernel size of middle conv layer at main path\n",
    "        filters: list of integers, the filterss of 3 conv layer at main path\n",
    "        stage: integer, current stage label, used for generating layer names\n",
    "        block: 'a','b'..., current block label, used for generating layer names\n",
    "    # Returns\n",
    "        Output tensor for the block.\n",
    "    Note that from stage 3, the first conv layer at main path is with strides=(2,2)\n",
    "    And the shortcut should have strides=(2,2) as well\n",
    "    \"\"\"\n",
    "    filters1, filters2, filters3 = filters\n",
    "    if K.image_data_format() == 'channels_last':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    x = Conv2D(filters1, (1, 1), strides=strides,\n",
    "               name=conv_name_base + '2a')(input_tensor)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(filters2, kernel_size, padding='same',\n",
    "               name=conv_name_base + '2b')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(filters3, (1, 1), name=conv_name_base + '2c')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
    "    shortcut = Conv2D(filters3, (1, 1), strides=strides,\n",
    "                      name=conv_name_base + '1')(input_tensor)\n",
    "    shortcut = BatchNormalization(axis=bn_axis, name=bn_name_base + '1')(shortcut)\n",
    "    x = layers.add([x, shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T04:17:04.036695Z",
     "iopub.status.busy": "2022-12-02T04:17:04.036062Z",
     "iopub.status.idle": "2022-12-02T04:17:04.061591Z",
     "shell.execute_reply": "2022-12-02T04:17:04.060608Z",
     "shell.execute_reply.started": "2022-12-02T04:17:04.036654Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def cvam_block(x,x1,x2, ratio=8):\n",
    "  \"\"\"Contains the implementation of Convolutional Block Attention Module(CBAM) block.\n",
    "  As described in https://arxiv.org/abs/1807.06521.\n",
    "  \"\"\"\n",
    "  #print('before',x)\n",
    "  c_map = channel_attention2(x,x2, ratio)\n",
    "  #print ('after',x_enhanced)\n",
    "  s_map = spatial_attention2(x,x1)\n",
    "  return multiply([x, 1+s_map,1+c_map])\n",
    "  #x=RMLO\n",
    "  #x1=LMLO\n",
    "  #x2=RCC\n",
    "  #x3=LCC\n",
    "def channel_attention2(x,x2, ratio=8):\n",
    "  features=[x,x2]\n",
    "  channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
    "  channel = x.shape[channel_axis]\t\n",
    "  #channel = input_feature.shape\n",
    "  shared_layer_one = Dense(channel//ratio,\n",
    "              activation='relu',\n",
    "              kernel_initializer='he_normal',\n",
    "              use_bias=True,\n",
    "              bias_initializer='zeros')\n",
    "  shared_layer_two = Dense(channel,\n",
    "              kernel_initializer='he_normal',\n",
    "              use_bias=True,\n",
    "              bias_initializer='zeros')\n",
    "\n",
    "  avg_pool = GlobalAveragePooling2D()(x)    \n",
    "  avg_pool = Reshape((1,1,channel))(avg_pool)\n",
    "  assert avg_pool.shape[1:] == (1,1,channel)\n",
    "  avg_pool = shared_layer_one(avg_pool)\n",
    "  assert avg_pool.shape[1:] == (1,1,channel//ratio)\n",
    "  avg_pool = shared_layer_two(avg_pool)\n",
    "  assert avg_pool.shape[1:] == (1,1,channel)\n",
    "\n",
    "  max_pool = GlobalMaxPooling2D()(x)\n",
    "  max_pool = Reshape((1,1,channel))(max_pool)\n",
    "  assert max_pool.shape[1:] == (1,1,channel)\n",
    "  max_pool = shared_layer_one(max_pool)\n",
    "  assert max_pool.shape[1:] == (1,1,channel//ratio)\n",
    "  max_pool = shared_layer_two(max_pool)\n",
    "  assert max_pool.shape[1:] == (1,1,channel)\n",
    "\n",
    "  avg_pool1 = GlobalAveragePooling2D()(x2)    \n",
    "  avg_pool1 = Reshape((1,1,channel))(avg_pool1)\n",
    "  assert avg_pool1.shape[1:] == (1,1,channel)\n",
    "  avg_pool1 = shared_layer_one(avg_pool1)\n",
    "  assert avg_pool1.shape[1:] == (1,1,channel//ratio)\n",
    "  avg_pool1 = shared_layer_two(avg_pool1)\n",
    "  assert avg_pool1.shape[1:] == (1,1,channel)\n",
    "\n",
    "  max_pool1 = GlobalMaxPooling2D()(x2)\n",
    "  max_pool1 = Reshape((1,1,channel))(max_pool1)\n",
    "  assert max_pool1.shape[1:] == (1,1,channel)\n",
    "  max_pool1 = shared_layer_one(max_pool1)\n",
    "  assert max_pool1.shape[1:] == (1,1,channel//ratio)\n",
    "  max_pool1 = shared_layer_two(max_pool1)\n",
    "  assert max_pool1.shape[1:] == (1,1,channel)\n",
    "    \n",
    "  #concat = Concatenate(axis=1)([avg_pool, max_pool, avg_pool1, max_pool1])\n",
    "  concat = Concatenate(axis=3)([avg_pool, max_pool, avg_pool1, max_pool1])\n",
    "    \n",
    "  print('concat', concat)\n",
    "  print('avg_pool',avg_pool)\n",
    "  cbam_feature=Dense(x.shape[3])(concat)\n",
    "  print ('after dense1',cbam_feature)\n",
    "  cbam_feature = Activation('relu')(cbam_feature)\n",
    "  cbam_feature=Dense(x.shape[3])(concat)\n",
    "  print ('after dense2',cbam_feature)\n",
    "  #sum = Add()([avg_pool,max_pool,avg_pool1,max_pool1])\n",
    "  #print ('sum', sum)\n",
    "  cbam_feature = Activation('sigmoid')(cbam_feature)\n",
    "  print (cbam_feature)\n",
    "  if K.image_data_format() == \"channels_first\":\n",
    "    cbam_feature = Permute((3, 1, 2))(cbam_feature)\n",
    "  \n",
    "  return cbam_feature\n",
    "\n",
    "def spatial_attention2(x,x1):\n",
    "  kernel_size = 7\n",
    "\t\n",
    "  if K.image_data_format() == \"channels_first\":\n",
    "    channel = x.shape[1]\n",
    "    cbam_feature = Permute((2,3,1))(x)\n",
    "  else:\n",
    "    channel = x.shape[-1]\n",
    "    cbam_feature = x\n",
    "\t\n",
    "  avg_pool = Lambda(lambda x: K.mean(x, axis=3, keepdims=True))(cbam_feature)\n",
    "  print ('avg pool v1',avg_pool)\n",
    "  assert avg_pool.shape[-1] == 1\n",
    "  max_pool = Lambda(lambda x: K.max(x, axis=3, keepdims=True))(cbam_feature)\n",
    "  assert max_pool.shape[-1] == 1\n",
    "\n",
    "  if K.image_data_format() == \"channels_first\":\n",
    "    channel = x1.shape[1]\n",
    "    cbam_feature = Permute((2,3,1))(x1)\n",
    "  else:\n",
    "    channel = x1.shape[-1]\n",
    "    cbam_feature = x1\n",
    "\n",
    "  avg_pool1 = Lambda(lambda x: K.mean(x, axis=3, keepdims=True))(x1)\n",
    "  print ('avg pool v2',avg_pool1)\n",
    "  assert avg_pool1.shape[-1] == 1\n",
    "  max_pool1 = Lambda(lambda x: K.max(x, axis=3, keepdims=True))(x1)\n",
    "  assert max_pool1.shape[-1] == 1\n",
    "\n",
    "  #concat = Concatenate(axis=1)([avg_pool, max_pool, avg_pool1, max_pool1])\n",
    "  concat = Concatenate(axis=3)([avg_pool, max_pool, avg_pool1, max_pool1])\n",
    "    \n",
    "  #concat = Concatenate(axis=3)([avg_pool, max_pool])\n",
    "  assert concat.shape[-1] == 4\n",
    "  cbam_feature = Conv2D(4, (3, 3), padding=\"same\")(concat)\n",
    "  cbam_feature = Activation('relu')(cbam_feature)\t\n",
    "  cbam_feature = Conv2D(1, (3, 3), padding=\"same\")(cbam_feature)\n",
    "  cbam_feature = Activation('sigmoid')(cbam_feature)\n",
    "  #print (cbam_feature)\t\n",
    "  assert cbam_feature.shape[-1] == 1\n",
    "  if K.image_data_format() == \"channels_first\":\n",
    "    cbam_feature = Permute((3, 1, 2))(cbam_feature)\n",
    "  #print (multiply([x, cbam_feature]))\n",
    "  return cbam_feature"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Declare a counter variable to keep track of what view we are in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewCount = 0\n",
    "x_cat = tf.zeros(shape=[4,dim[0],dim[1],3,1])\n",
    "y_cat = tf.zeros(shape=[4,dim[0],dim[1],3,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T04:17:04.064535Z",
     "iopub.status.busy": "2022-12-02T04:17:04.063886Z",
     "iopub.status.idle": "2022-12-02T04:17:04.116623Z",
     "shell.execute_reply": "2022-12-02T04:17:04.115598Z",
     "shell.execute_reply.started": "2022-12-02T04:17:04.064501Z"
    }
   },
   "outputs": [],
   "source": [
    "def MyResNet50(dimension,include_top=True, weights='imagenet',\n",
    "             input_tensor=None, input_shape=None,\n",
    "             pooling=None,\n",
    "             classes=1):\n",
    "    \"\"\"Instantiates the ResNet50 architecture.\n",
    "    Optionally loads weights pre-trained\n",
    "    on ImageNet. Note that when using TensorFlow,\n",
    "    for best performance you should set\n",
    "    `image_data_format=\"channels_last\"` in your Keras config\n",
    "    at ~/.keras/keras.json.\n",
    "    The model and the weights are compatible with both\n",
    "    TensorFlow and Theano. The data format\n",
    "    convention used by the model is the one\n",
    "    specified in your Keras config file.\n",
    "    # Arguments\n",
    "        include_top: whether to include the fully-connected\n",
    "            layer at the top of the network.\n",
    "        weights: one of `None` (random initialization)\n",
    "            or \"imagenet\" (pre-training on ImageNet).\n",
    "        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n",
    "            to use as image input for the model.\n",
    "        input_shape: optional shape tuple, only to be specified\n",
    "            if `include_top` is False (otherwise the input shape\n",
    "            has to be `(224, 224, 3)` (with `channels_last` data format)\n",
    "            or `(3, 224, 244)` (with `channels_first` data format).\n",
    "            It should have exactly 3 inputs channels,\n",
    "            and width and height should be no smaller than 197.\n",
    "            E.g. `(200, 200, 3)` would be one valid value.\n",
    "        pooling: Optional pooling mode for feature extraction\n",
    "            when `include_top` is `False`.\n",
    "            - `None` means that the output of the model will be\n",
    "                the 4D tensor output of the\n",
    "                last convolutional layer.\n",
    "            - `avg` means that global average pooling\n",
    "                will be applied to the output of the\n",
    "                last convolutional layer, and thus\n",
    "                the output of the model will be a 2D tensor.\n",
    "            - `max` means that global max pooling will\n",
    "                be applied.\n",
    "        classes: optional number of classes to classify images\n",
    "            into, only to be specified if `include_top` is True, and\n",
    "            if no `weights` argument is specified.\n",
    "    # Returns\n",
    "        A Keras model instance.\n",
    "    # Raises\n",
    "        ValueError: in case of invalid argument for `weights`,\n",
    "            or invalid input shape.\n",
    "    \"\"\"\n",
    "    if weights not in {'imagenet', None}:\n",
    "        raise ValueError('The `weights` argument should be either '\n",
    "                         '`None` (random initialization) or `imagenet` '\n",
    "                         '(pre-training on ImageNet).')\n",
    "\n",
    "    if weights == 'imagenet' and include_top and classes != 1000:\n",
    "        raise ValueError('If using `weights` as imagenet with `include_top`'\n",
    "                         ' as true, `classes` should be 1000')\n",
    "    #######################################\n",
    "    ##### Determine proper input shape ####\n",
    "    #######################################\n",
    "    input_shape = [dimension[1],dimension[0],3]\n",
    "    #input_shape = [4,dimension[0],dimension[1],3]\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = Input(shape=input_shape)\n",
    "    else:\n",
    "        if not K.is_keras_tensor(input_tensor):\n",
    "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "    if K.image_data_format() == 'channels_last':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "    \n",
    "    #x=img_input\n",
    "\n",
    "    \n",
    "    #x=img_input\n",
    "    x=img_input[:,0,:,:,:]\n",
    "    x1=x_cat[:,1,:,:,:]\n",
    "    x2=x_cat[:,2,:,:,:]\n",
    "    x3=x_cat[:,3,:,:,:]\n",
    "    \n",
    "    print (x.shape)\n",
    "    global viewCount\n",
    "    if(viewCount == 4):\n",
    "        viewCount = 0 # reset the counter\n",
    "    '''\n",
    "    if(viewCount == 1):\n",
    "        x=img_input[:,0,:,:,:]\n",
    "    elif(viewCount == 2):\n",
    "        x=img_input[:,1,:,:,:]\n",
    "    elif(viewCount == 3):\n",
    "        x=img_input[:,2,:,:,:]\n",
    "    elif(viewCount == 4):\n",
    "        x=img_input[:,3,:,:,:]\n",
    "        viewCount = 0 # reset the counter\n",
    "    '''\n",
    "    \n",
    "    #x=img_input[:,0,:,:,:]\n",
    "    #x1=img_input[:,1,:,:,:]\n",
    "    #x2=img_input[:,2,:,:,:]\n",
    "    \n",
    "    #x3=img_input[:,3,:,:,:]\n",
    "    #x_list = [x,x1,x2,x3]\n",
    "    #print ('after',x)\n",
    "    #for i in range(0,len(x_list)):\n",
    "        #x = x_list[i]\n",
    "\n",
    "    x = ZeroPadding2D((3, 3))(x)\n",
    "    x1 = ZeroPadding2D((3, 3))(x1)\n",
    "    x2 = ZeroPadding2D((3, 3))(x2)\n",
    "    x3 = ZeroPadding2D((3, 3))(x3)\n",
    "    #print ('first', x)\n",
    "    x = Conv2D(64, (7, 7), strides=(2, 2), name='conv1')(x)\n",
    "    x1 = Conv2D(64, (7, 7), strides=(2, 2), name='conv1_1')(x1)\n",
    "    x2 = Conv2D(64, (7, 7), strides=(2, 2), name='conv1_2')(x2)\n",
    "    x3 = Conv2D(64, (7, 7), strides=(2, 2), name='conv1_3')(x3)\n",
    "\n",
    "    x = BatchNormalization(axis=bn_axis, name='bn_conv1')(x)\n",
    "    x1 = BatchNormalization(axis=bn_axis, name='bn_conv1_1')(x1)\n",
    "    x2 = BatchNormalization(axis=bn_axis, name='bn_conv1_2')(x2)\n",
    "    x3 = BatchNormalization(axis=bn_axis, name='bn_conv1_3')(x3)\n",
    "\n",
    "    x = Activation('relu')(x)\n",
    "    x1 = Activation('relu')(x1)\n",
    "    x2 = Activation('relu')(x2)\n",
    "    x3 = Activation('relu')(x3)\n",
    "\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "    x1 = MaxPooling2D((3, 3), strides=(2, 2))(x1)\n",
    "    x2 = MaxPooling2D((3, 3), strides=(2, 2))(x2)\n",
    "    x3 = MaxPooling2D((3, 3), strides=(2, 2))(x3)\n",
    "\n",
    "    x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))\n",
    "    x1 = conv_block(x1, 3, [64, 64, 256], stage=2, block='a1', strides=(1, 1))\n",
    "    x2 = conv_block(x2, 3, [64, 64, 256], stage=2, block='a2', strides=(1, 1))\n",
    "    x3 = conv_block(x3, 3, [64, 64, 256], stage=2, block='a3', strides=(1, 1))\n",
    "\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='b')\n",
    "    x1 = identity_block(x1, 3, [64, 64, 256], stage=2, block='b1')\n",
    "    x2 = identity_block(x2, 3, [64, 64, 256], stage=2, block='b2')\n",
    "    x3 = identity_block(x3, 3, [64, 64, 256], stage=2, block='b3')\n",
    "\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='c')\n",
    "    x1 = identity_block(x1, 3, [64, 64, 256], stage=2, block='c1')\n",
    "    x2 = identity_block(x2, 3, [64, 64, 256], stage=2, block='c2')\n",
    "    x3 = identity_block(x3, 3, [64, 64, 256], stage=2, block='c3')\n",
    "    #print ('x1',x1.shape[3])\n",
    "    \n",
    "    #x = cbam_block(x)\n",
    "\n",
    "\n",
    "    x = conv_block(x, 3, [128, 128, 512], stage=3, block='a')\n",
    "    x1 = conv_block(x1, 3, [128, 128, 512], stage=3, block='a1')\n",
    "    x2 = conv_block(x2, 3, [128, 128, 512], stage=3, block='a2')\n",
    "    x3 = conv_block(x2, 3, [128, 128, 512], stage=3, block='a3')\n",
    "\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='b')\n",
    "    x1 = identity_block(x1, 3, [128, 128, 512], stage=3, block='b1')\n",
    "    x2 = identity_block(x2, 3, [128, 128, 512], stage=3, block='b2')\n",
    "    x3 = identity_block(x3, 3, [128, 128, 512], stage=3, block='b3')\n",
    "\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='c')\n",
    "    x1 = identity_block(x1, 3, [128, 128, 512], stage=3, block='c1')\n",
    "    x2 = identity_block(x2, 3, [128, 128, 512], stage=3, block='c2')\n",
    "    x3 = identity_block(x3, 3, [128, 128, 512], stage=3, block='c3')\n",
    "\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='d')\n",
    "    x1 = identity_block(x1, 3, [128, 128, 512], stage=3, block='d1')\n",
    "    x2 = identity_block(x2, 3, [128, 128, 512], stage=3, block='d2')\n",
    "    x3 = identity_block(x3, 3, [128, 128, 512], stage=3, block='d3')\n",
    "    #x=img_input[:,0,:,:,:]\n",
    "    #x = cbam_block(x)\n",
    "\n",
    "    ########\n",
    "    ### TODO: x1,x2,x3 have the wrong size, due to not being run through the conv layers\n",
    "    ###\n",
    "    #l-cc==x_cat[:,0,:,:,:]\n",
    "    #l-mlo==x_cat[:,1,:,:,:]\n",
    "    #r-cc==x_cat[:,2,:,:,:]\n",
    "    #r-mlo==x_cat[:,3,:,:,:]\n",
    "\n",
    "    if(viewCount == 1):\n",
    "         # x1 == r-cc, x2 == l-mlo\n",
    "         x = cvam_block(x,x2,x1)\n",
    "    elif(viewCount == 2):\n",
    "         # x1 == r-mlo, x2 == l-cc\n",
    "         x = cvam_block(x,x3,x)\n",
    "    elif(viewCount == 3):\n",
    "         # x1 == l-cc, r-mlo\n",
    "         x = cvam_block(x,x,x3)\n",
    "    elif(viewCount == 0): # fourth image, reset counter done prior\n",
    "         # x1 == l-mlo, r-cc\n",
    "         x = cvam_block(x,x1,x2)\n",
    "    \n",
    "    #x = cvam_block(x,x1,x2)\n",
    "    \n",
    "    \n",
    "    #x1 = cvam_block(x1,x,x3)\n",
    "    #x2 = cvam_block(x2,x3,x)\n",
    "    # x3 = cvam_block(x3,x2,x1)\n",
    "    #for i in range(0,len(x_list)):\n",
    "       # x = x_list[i]\n",
    "\n",
    "    x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a')\n",
    "    x1 = conv_block(x1, 3, [256, 256, 1024], stage=4, block='a1')\n",
    "    x2 = conv_block(x2, 3, [256, 256, 1024], stage=4, block='a2')\n",
    "    x3 = conv_block(x3, 3, [256, 256, 1024], stage=4, block='a3')\n",
    "\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b')\n",
    "    x1 = identity_block(x1, 3, [256, 256, 1024], stage=4, block='b1')\n",
    "    x2 = identity_block(x2, 3, [256, 256, 1024], stage=4, block='b2')\n",
    "    x3 = identity_block(x3, 3, [256, 256, 1024], stage=4, block='b3')\n",
    "\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='c')\n",
    "    x1 = identity_block(x1, 3, [256, 256, 1024], stage=4, block='c1')\n",
    "    x2 = identity_block(x2, 3, [256, 256, 1024], stage=4, block='c2')\n",
    "    x3 = identity_block(x3, 3, [256, 256, 1024], stage=4, block='c3')\n",
    "\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='d')\n",
    "    x1 = identity_block(x1, 3, [256, 256, 1024], stage=4, block='d1')\n",
    "    x2 = identity_block(x2, 3, [256, 256, 1024], stage=4, block='d2')\n",
    "    x3 = identity_block(x3, 3, [256, 256, 1024], stage=4, block='d3')\n",
    "\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='e')\n",
    "    x1 = identity_block(x1, 3, [256, 256, 1024], stage=4, block='e1')\n",
    "    x2 = identity_block(x2, 3, [256, 256, 1024], stage=4, block='e2')\n",
    "    x3 = identity_block(x3, 3, [256, 256, 1024], stage=4, block='e3')\n",
    "\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='f')\n",
    "    x1 = identity_block(x1, 3, [256, 256, 1024], stage=4, block='f1')\n",
    "    x2 = identity_block(x2, 3, [256, 256, 1024], stage=4, block='f2')\n",
    "    x3 = identity_block(x3, 3, [256, 256, 1024], stage=4, block='f3')\n",
    "    #x=img_input[:,0,:,:,:]\n",
    "    #x = cbam_block(x)\n",
    "    \n",
    "    #l-cc==x_cat[:,0,:,:,:]\n",
    "    #l-mlo==x_cat[:,1,:,:,:]\n",
    "    #r-cc==x_cat[:,2,:,:,:]\n",
    "    #r-mlo==x_cat[:,3,:,:,:]\n",
    "\n",
    "    if(viewCount == 1):\n",
    "         # x1 == r-cc, x2 == l-mlo\n",
    "         x = cvam_block(x,x2,x1)\n",
    "    elif(viewCount == 2):\n",
    "         # x1 == r-mlo, x2 == l-cc\n",
    "         x = cvam_block(x,x3,x)\n",
    "    elif(viewCount == 3):\n",
    "         # x1 == l-cc, r-mlo\n",
    "         x = cvam_block(x,x,x3)\n",
    "    elif(viewCount == 0): # fourth image, reset counter done prior\n",
    "         # x1 == l-mlo, r-cc\n",
    "         x = cvam_block(x,x1,x2)\n",
    "    \n",
    "    \n",
    "\n",
    "    #x = cvam_block(x,x1,x2)\n",
    "    #x1 = cvam_block(x1,x,x3)\n",
    "    #x2 = cvam_block(x2,x3,x)\n",
    "    # x3 = cvam_block(x3,x2,x1)\n",
    "    #for i in range(0,len(x_list)):\n",
    "        #x = x_list[i]\n",
    "\n",
    "    x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a')\n",
    "    x1 = conv_block(x1, 3, [512, 512, 2048], stage=5, block='a1')\n",
    "    x2 = conv_block(x2, 3, [512, 512, 2048], stage=5, block='a2')\n",
    "    x3 = conv_block(x3, 3, [512, 512, 2048], stage=5, block='a3')\n",
    "\n",
    "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b')\n",
    "    x1 = identity_block(x1, 3, [512, 512, 2048], stage=5, block='b1')\n",
    "    x2 = identity_block(x2, 3, [512, 512, 2048], stage=5, block='b2')\n",
    "    x3 = identity_block(x3, 3, [512, 512, 2048], stage=5, block='b3')\n",
    "\n",
    "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c')\n",
    "    x1 = identity_block(x1, 3, [512, 512, 2048], stage=5, block='c1')\n",
    "    x2 = identity_block(x2, 3, [512, 512, 2048], stage=5, block='c2')\n",
    "    x3 = identity_block(x3, 3, [512, 512, 2048], stage=5, block='c3')\n",
    "    #x=img_input[:,0,:,:,:]\n",
    "    #x = cbam_block(x)\n",
    "    \n",
    "    #l-cc==x_cat[:,0,:,:,:]\n",
    "    #l-mlo==x_cat[:,1,:,:,:]\n",
    "    #r-cc==x_cat[:,2,:,:,:]\n",
    "    #r-mlo==x_cat[:,3,:,:,:]\n",
    "\n",
    "    if(viewCount == 1):\n",
    "         # x1 == r-cc, x2 == l-mlo\n",
    "         x = cvam_block(x,x2,x1)\n",
    "    elif(viewCount == 2):\n",
    "         # x1 == r-mlo, x2 == l-cc\n",
    "         x = cvam_block(x,x3,x)\n",
    "    elif(viewCount == 3):\n",
    "         # x1 == l-cc, r-mlo\n",
    "         x = cvam_block(x,x,x3)\n",
    "    elif(viewCount == 0): # fourth image, reset counter done prior\n",
    "         # x1 == l-mlo, r-cc\n",
    "         x = cvam_block(x,x1,x2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #x = cvam_block(x,x1,x2)\n",
    "    #x1 = cvam_block(x1,x,x3)\n",
    "    #x2 = cvam_block(x2,x3,x)\n",
    "    # x3 = cvam_block(x3,x2,x1)\n",
    "    #for i in range(0,len(x_list)):\n",
    "       # x = x_list[i]\n",
    "\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x1 = GlobalAveragePooling2D()(x1)\n",
    "    x2 = GlobalAveragePooling2D()(x2)\n",
    "    x3 = GlobalAveragePooling2D()(x3)\n",
    "    \n",
    "    x = Dense(256,activation='PReLU')(x)\n",
    "    x1 = Dense(256,activation='PReLU')(x1)\n",
    "    x2 = Dense(256,activation='PReLU')(x2)\n",
    "    x3 = Dense(256,activation='PReLU')(x3)\n",
    "    \n",
    "    x = Dropout(.5)(x)\n",
    "    x1 = Dropout(.5)(x1)\n",
    "    x2 = Dropout(.5)(x2)\n",
    "    x3 = Dropout(.5)(x3)\n",
    "    \n",
    "    x=BatchNormalization()(x)\n",
    "    x1=BatchNormalization()(x1)\n",
    "    x2=BatchNormalization()(x2)\n",
    "    x3=BatchNormalization()(x3)\n",
    "    \n",
    "    x = Dense(256,activation='PReLU')(x)\n",
    "    x1 = Dense(256,activation='PReLU')(x1)\n",
    "    x2 = Dense(256,activation='PReLU')(x2)\n",
    "    x3 = Dense(256,activation='PReLU')(x3)\n",
    "    \n",
    "    x = Dropout(.5)(x)\n",
    "    x1 = Dropout(.5)(x1)\n",
    "    x2 = Dropout(.5)(x2)\n",
    "    x3 = Dropout(.5)(x3)\n",
    "    \n",
    "    x=BatchNormalization()(x)\n",
    "    x1=BatchNormalization()(x1)\n",
    "    x2=BatchNormalization()(x2)\n",
    "    x3=BatchNormalization()(x3)\n",
    "    \n",
    "    x = Dense(3,activation='sigmoid')(x)\n",
    "    x1 = Dense(3,activation='sigmoid')(x1)\n",
    "    x2 = Dense(3,activation='sigmoid')(x2)\n",
    "    x3 = Dense(3,activation='sigmoid')(x3)\n",
    "    \n",
    "    x=tf.concat([x,x1,x2,x3],1)\n",
    "    print(x)\n",
    "\n",
    "    #print (input_tensor, img_input)\n",
    "    if input_tensor is not None:\n",
    "        inputs = get_source_inputs(input_tensor)\n",
    "    else:\n",
    "        inputs = img_input\n",
    "    # Create model.\n",
    "    model = Model(inputs=inputs, outputs=x, name='resnet50')\n",
    "\n",
    "    # load weights\n",
    "    if weights == 'imagenet':\n",
    "        if include_top:\n",
    "            weights_path = get_file('resnet50_weights_tf_dim_ordering_tf_kernels.h5',\n",
    "                                    WEIGHTS_PATH,\n",
    "                                    cache_subdir='models',\n",
    "                                    md5_hash='a7b3fe01876f51b976af0dea6bc144eb')\n",
    "        else:\n",
    "            weights_path = get_file('resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "                                    WEIGHTS_PATH_NO_TOP,\n",
    "                                    cache_subdir='models',\n",
    "                                    md5_hash='a268eb855778b3df3c7506639542a6af')\n",
    "        model.load_weights(weights_path, by_name = True, skip_mismatch = True)\n",
    "        if K.backend() == 'theano':\n",
    "            layer_utils.convert_all_kernels_in_model(model)\n",
    "\n",
    "        if K.image_data_format() == 'channels_first':\n",
    "            if include_top:\n",
    "                maxpool = model.get_layer(name='avg_pool')\n",
    "                shape = maxpool.output_shape[1:]\n",
    "                dense = model.get_layer(name='fc1000')\n",
    "                layer_utils.convert_dense_weights_data_format(dense, shape, 'channels_first')\n",
    "\n",
    "            if K.backend() == 'tensorflow':\n",
    "                warnings.warn('You are using the TensorFlow backend, yet you ')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T04:17:04.118131Z",
     "iopub.status.busy": "2022-12-02T04:17:04.117776Z",
     "iopub.status.idle": "2022-12-02T04:17:09.209171Z",
     "shell.execute_reply": "2022-12-02T04:17:09.208105Z",
     "shell.execute_reply.started": "2022-12-02T04:17:04.118097Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 300, 600, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "base_model = MyResNet50(dim,weights='imagenet', include_top=False)\n",
    "#base_model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###########################################<br>\n",
    "## Define Preprocessing Functions ####<br>\n",
    "###########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T04:17:12.855713Z",
     "iopub.status.busy": "2022-12-02T04:17:12.855301Z",
     "iopub.status.idle": "2022-12-02T04:17:12.862956Z",
     "shell.execute_reply": "2022-12-02T04:17:12.860888Z",
     "shell.execute_reply.started": "2022-12-02T04:17:12.855679Z"
    }
   },
   "outputs": [],
   "source": [
    "def CropBorders(img):\n",
    "    nrows, ncols = img.shape[0],img.shape[1]\n",
    "    # Get the start and end rows and columns\n",
    "    l_crop = int(ncols * 0.01)\n",
    "    r_crop = int(ncols * (1 - 0.01))\n",
    "    u_crop = int(nrows * 0.04)\n",
    "    d_crop = int(nrows * (1 - 0.04))\n",
    "    cropped_img = img[u_crop:d_crop, l_crop:r_crop]    \n",
    "    return cropped_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T04:17:13.075126Z",
     "iopub.status.busy": "2022-12-02T04:17:13.074542Z",
     "iopub.status.idle": "2022-12-02T04:17:13.081642Z",
     "shell.execute_reply": "2022-12-02T04:17:13.080772Z",
     "shell.execute_reply.started": "2022-12-02T04:17:13.075087Z"
    }
   },
   "outputs": [],
   "source": [
    "def OwnGlobalBinarise(img, thresh, maxval):       \n",
    "    binarised_img = np.zeros(img.shape, np.uint8)\n",
    "    binarised_img[img >= thresh] = maxval    \n",
    "    return binarised_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T04:17:13.280304Z",
     "iopub.status.busy": "2022-12-02T04:17:13.279997Z",
     "iopub.status.idle": "2022-12-02T04:17:13.286320Z",
     "shell.execute_reply": "2022-12-02T04:17:13.285280Z",
     "shell.execute_reply.started": "2022-12-02T04:17:13.280277Z"
    }
   },
   "outputs": [],
   "source": [
    "def OpenMask(mask, ksize=(23, 23), operation=\"open\"):\n",
    "    kernel = cv2.getStructuringElement(shape=cv2.MORPH_RECT, ksize=ksize)    \n",
    "    if operation == \"open\":\n",
    "        edited_mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "    elif operation == \"close\":\n",
    "        edited_mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)    \n",
    "    # Then dilate\n",
    "    edited_mask = cv2.morphologyEx(edited_mask, cv2.MORPH_DILATE, kernel)\n",
    "    return edited_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T04:17:13.506793Z",
     "iopub.status.busy": "2022-12-02T04:17:13.505807Z",
     "iopub.status.idle": "2022-12-02T04:17:13.513114Z",
     "shell.execute_reply": "2022-12-02T04:17:13.511960Z",
     "shell.execute_reply.started": "2022-12-02T04:17:13.506750Z"
    }
   },
   "outputs": [],
   "source": [
    "def SortContoursByArea(contours, reverse=True):   \n",
    "    '''\n",
    "    ----------\n",
    "    contours : {list}\n",
    "        The list of contours to sort.        \n",
    "    Returns\n",
    "    -------\n",
    "    sorted_contours : {list}\n",
    "        The list of contours sorted by contour area in descending\n",
    "        order.\n",
    "    bounding_boxes : {list}\n",
    "        The list of bounding boxes ordered corresponding to the\n",
    "        contours in `sorted_contours`.\n",
    "    '''   \n",
    "    # Sort contours based on contour area.\n",
    "    sorted_contours = sorted(contours, key=cv2.contourArea, reverse=True)    \n",
    "    # Construct the list of corresponding bounding boxes.\n",
    "    bounding_boxes = [cv2.boundingRect(c) for c in sorted_contours]\n",
    "    return sorted_contours, bounding_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T04:17:13.947784Z",
     "iopub.status.busy": "2022-12-02T04:17:13.946911Z",
     "iopub.status.idle": "2022-12-02T04:17:13.955455Z",
     "shell.execute_reply": "2022-12-02T04:17:13.954341Z",
     "shell.execute_reply.started": "2022-12-02T04:17:13.947735Z"
    }
   },
   "outputs": [],
   "source": [
    "def DrawContourID(img, bounding_box, contour_id):    \n",
    "    '''\n",
    "    ----------\n",
    "    img: {numpy.ndarray}\n",
    "        The image to draw the contour on.\n",
    "    bounding_box : {tuple of int}\n",
    "        The bounding_rect of the given contour.\n",
    "    contour_id : {int or float}\n",
    "        The corresponding ID of the given `contour`.        \n",
    "    Returns\n",
    "    -------\n",
    "    img : {numpy.ndarray}\n",
    "        The image after the `contour` and its ID is drawn on.\n",
    "    ''' \n",
    "    # Center of bounding_rect.\n",
    "    x, y, w, h = bounding_box\n",
    "    center = ( ((x + w) // 2), ((y + h) // 2) )\n",
    "    # Draw the countour number on the image\n",
    "    cv2.putText(img=img,\n",
    "                text=f\"{contour_id}\",\n",
    "                org=center, # Bottom-left corner of the text string in the image.\n",
    "                fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                fontScale=10, \n",
    "                color=(255, 255, 255),\n",
    "                thickness=40)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T04:17:14.508741Z",
     "iopub.status.busy": "2022-12-02T04:17:14.508335Z",
     "iopub.status.idle": "2022-12-02T04:17:14.523191Z",
     "shell.execute_reply": "2022-12-02T04:17:14.522277Z",
     "shell.execute_reply.started": "2022-12-02T04:17:14.508705Z"
    }
   },
   "outputs": [],
   "source": [
    "def XLargestBlobs(mask, top_X=None):\n",
    "    \n",
    "    '''\n",
    "    ----------\n",
    "    mask : {numpy.ndarray, dtype=np.uint8}\n",
    "        The mask to get the top X largest blobs.\n",
    "    top_X : {int}\n",
    "        The top X contours to keep based on contour area\n",
    "        ranked in decesnding order.\n",
    "    Returns\n",
    "    -------\n",
    "    n_contours : {int}\n",
    "        The number of contours found in the given `mask`.\n",
    "    X_largest_blobs : {numpy.ndarray}\n",
    "        The corresponding mask of the image containing only\n",
    "        the top X largest contours in white.\n",
    "    '''        \n",
    "    # Find all contours from binarised image.\n",
    "    # Note: parts of the image that you want to get should be white.\n",
    "    contours, hierarchy = cv2.findContours(image=mask,\n",
    "                                           mode=cv2.RETR_EXTERNAL,\n",
    "                                           method=cv2.CHAIN_APPROX_NONE)   \n",
    "    n_contours = len(contours)    \n",
    "    # Only get largest blob if there is at least 1 contour.\n",
    "    if n_contours > 0:        \n",
    "        # Make sure that the number of contours to keep is at most equal \n",
    "        # to the number of contours present in the mask.\n",
    "        if n_contours < top_X or top_X == None:\n",
    "            top_X = n_contours        \n",
    "        # Sort contours based on contour area.\n",
    "        sorted_contours, bounding_boxes = SortContoursByArea(contours=contours,\n",
    "                                                             reverse=True)        \n",
    "        # Get the top X largest contours.\n",
    "        X_largest_contours = sorted_contours[0:top_X]        \n",
    "        # Create black canvas to draw contours on.\n",
    "        to_draw_on = np.zeros(mask.shape, np.uint8)        \n",
    "        # Draw contours in X_largest_contours.\n",
    "        X_largest_blobs = cv2.drawContours(image=to_draw_on, # Draw the contours on `to_draw_on`.\n",
    "                                           contours=X_largest_contours, # List of contours to draw.\n",
    "                                           contourIdx=-1, # Draw all contours in `contours`.\n",
    "                                           color=1, # Draw the contours in white.\n",
    "                                           thickness=-1) # Thickness of the contour lines.        \n",
    "    return n_contours, X_largest_blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T04:17:15.417393Z",
     "iopub.status.busy": "2022-12-02T04:17:15.416713Z",
     "iopub.status.idle": "2022-12-02T04:17:15.422898Z",
     "shell.execute_reply": "2022-12-02T04:17:15.421612Z",
     "shell.execute_reply.started": "2022-12-02T04:17:15.417355Z"
    }
   },
   "outputs": [],
   "source": [
    "def ApplyMask(img, mask):   \n",
    "    '''\n",
    "    ----------\n",
    "    img : {numpy.ndarray}\n",
    "        The image to mask.\n",
    "    mask : {numpy.ndarray, dtype=np.uint8}\n",
    "        The mask to apply.        \n",
    "    Returns\n",
    "    -------\n",
    "    masked_img: {numpy.ndarray}\n",
    "        The masked image.\n",
    "    '''   \n",
    "    masked_img = img.copy()\n",
    "    masked_img[mask == 0] = 0    \n",
    "    return masked_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T04:17:16.151420Z",
     "iopub.status.busy": "2022-12-02T04:17:16.151066Z",
     "iopub.status.idle": "2022-12-02T04:17:16.158123Z",
     "shell.execute_reply": "2022-12-02T04:17:16.157146Z",
     "shell.execute_reply.started": "2022-12-02T04:17:16.151380Z"
    }
   },
   "outputs": [],
   "source": [
    "def HorizontalFlip(mask):    \n",
    "    '''\n",
    "    ----------\n",
    "    mask : {numpy.ndarray, dtype=np.uint8}\n",
    "        The corresponding mask of the CC image to flip.\n",
    "    Returns\n",
    "    -------\n",
    "    horizontal_flip : {boolean}\n",
    "        True means need to flip horizontally,\n",
    "        False means otherwise.\n",
    "    '''    \n",
    "    # Get number of rows and columns in the image.\n",
    "    nrows, ncols = mask.shape\n",
    "    x_center = ncols // 2\n",
    "    y_center = nrows // 2    \n",
    "    # Sum down each column.\n",
    "    col_sum = mask.sum(axis=0)\n",
    "    # Sum across each row.\n",
    "    row_sum = mask.sum(axis=1)    \n",
    "    left_sum = sum(col_sum[0:x_center])\n",
    "    right_sum = sum(col_sum[x_center:-1])\n",
    "    top_sum = sum(row_sum[0:y_center])\n",
    "    bottom_sum = sum(row_sum[y_center:-1])    \n",
    "    if left_sum < right_sum:\n",
    "        horizontal_flip = True\n",
    "    else:\n",
    "        horizontal_flip = False        \n",
    "    return horizontal_flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T04:17:16.873512Z",
     "iopub.status.busy": "2022-12-02T04:17:16.872797Z",
     "iopub.status.idle": "2022-12-02T04:17:16.879942Z",
     "shell.execute_reply": "2022-12-02T04:17:16.878891Z",
     "shell.execute_reply.started": "2022-12-02T04:17:16.873474Z"
    }
   },
   "outputs": [],
   "source": [
    "def clahe(img, clip=2.0, tile=(8, 8)):   \n",
    "    '''\n",
    "    ----------\n",
    "    img : {numpy.ndarray}\n",
    "        The image to edit.\n",
    "    clip : {int or floa}\n",
    "        Threshold for contrast limiting.\n",
    "    tile : {tuple (int, int)}\n",
    "        Size of grid for histogram equalization. Input\n",
    "        image will be divided into equally sized\n",
    "        rectangular tiles. `tile` defines the number of\n",
    "        tiles in row and column.    \n",
    "    Returns\n",
    "    -------\n",
    "    clahe_img : {numpy.ndarray}\n",
    "        The edited image.\n",
    "   '''    \n",
    "    # Convert to uint8.\n",
    "    # img = skimage.img_as_ubyte(img)\n",
    "    img = cv2.normalize(\n",
    "        img,\n",
    "        None,\n",
    "        alpha=0,\n",
    "        beta=255,\n",
    "        norm_type=cv2.NORM_MINMAX,\n",
    "        dtype=cv2.CV_32F,\n",
    "    )\n",
    "    img_uint8 = img.astype(\"uint8\")\n",
    "    clahe_create = cv2.createCLAHE(clipLimit=clip, tileGridSize=tile)\n",
    "    clahe_img = clahe_create.apply(img_uint8)\n",
    "    return clahe_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T04:17:17.618539Z",
     "iopub.status.busy": "2022-12-02T04:17:17.617817Z",
     "iopub.status.idle": "2022-12-02T04:17:17.625550Z",
     "shell.execute_reply": "2022-12-02T04:17:17.624351Z",
     "shell.execute_reply.started": "2022-12-02T04:17:17.618502Z"
    }
   },
   "outputs": [],
   "source": [
    "def pad(img):\n",
    "    nrows, ncols, nchannels = img.shape\n",
    "    # If padding is required...\n",
    "    if nrows != ncols:\n",
    "        # Take the longer side as the target shape.\n",
    "        if ncols < nrows:\n",
    "            target_shape = (nrows, nrows,nchannels)\n",
    "        elif nrows < ncols:\n",
    "            target_shape = (ncols, ncols,nchannels)\n",
    "        # pad.\n",
    "        padded_img = np.zeros(shape=target_shape)\n",
    "        padded_img[:nrows, :ncols, :] = img\n",
    "    # If padding is not required...\n",
    "    elif nrows == ncols:\n",
    "        # Return original image.\n",
    "        padded_img = img\n",
    "    return cv2.resize(padded_img,dim)\n",
    "\t\n",
    "#############################################\n",
    "#### Define ImageDataGenerator Functions ####\n",
    "#############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T04:17:19.333656Z",
     "iopub.status.busy": "2022-12-02T04:17:19.332750Z",
     "iopub.status.idle": "2022-12-02T04:17:19.345612Z",
     "shell.execute_reply": "2022-12-02T04:17:19.344535Z",
     "shell.execute_reply.started": "2022-12-02T04:17:19.333617Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocessing_fun(img):\n",
    "    #Combines all the transformations\n",
    "    #img = cv2.imread(filename)\n",
    "    crop_img = CropBorders(img[:,:,0])\n",
    "    norm = np.zeros((crop_img.shape[0],crop_img.shape[1]))\n",
    "    crop_img=cv2.normalize( crop_img,norm,alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "    # Changed bin_img to 0.25 from 0.15\n",
    "    bin_img = OwnGlobalBinarise(img=crop_img,thresh=0.20, maxval=1.0)\n",
    "    mask_img = OpenMask(mask=bin_img, ksize=(2, 2), operation=\"open\")\n",
    "    _, blob_img = XLargestBlobs(mask=np.array(mask_img), top_X=1)\n",
    "    processed_img = ApplyMask(img=crop_img, mask=blob_img)\n",
    "    horizontal_flip = HorizontalFlip(mask=blob_img)\n",
    "    if horizontal_flip:\n",
    "        flipped_img = np.fliplr(processed_img)\n",
    "    else:\n",
    "        flipped_img = processed_img\n",
    "    norm = np.zeros((flipped_img.shape[0],flipped_img.shape[1]))\n",
    "    norm_image = cv2.normalize(flipped_img,norm,0,255,cv2.NORM_MINMAX)\n",
    "    clahe_cv = cv2.createCLAHE(clipLimit =2.0, tileGridSize=(8,8))\n",
    "    norm_image=clahe_cv.apply(norm_image.astype(np.uint8))\n",
    "    #norm_image=cv2.normalize(norm_image,norm,alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "    norm3=np.zeros([norm_image.shape[0],norm_image.shape[1],3])\n",
    "    norm3[:,:,0]=norm_image\n",
    "    norm3[:,:,1]=norm_image\n",
    "    norm3[:,:,2]=norm_image\n",
    "    norm3=cv2.resize(norm3,(300,600))\n",
    "    return norm3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_image_data_generator(generator,directory, batch_size, img_height,img_width):\n",
    "    \n",
    "    generator_X = generator.flow_from_directory(directory,\n",
    "                                          target_size = (img_width, img_height),\n",
    "                                          class_mode = 'categorical',\n",
    "                                          batch_size = batch_size,\n",
    "                                          shuffle=False)\n",
    "    \n",
    "\n",
    "    while True:\n",
    "        #x=\n",
    "        x1,y1 = (generator_X[0])\n",
    "        x2,y2 = (generator_X.next())\n",
    "        x3,y3 = (generator_X.next())\n",
    "        x4,y4 = (generator_X.next())\n",
    "        x1=tf.expand_dims(x1,1)\n",
    "        x2=tf.expand_dims(x2,1)\n",
    "        x3=tf.expand_dims(x3,1)\n",
    "        x4=tf.expand_dims(x4,1)\n",
    "        #y1=tf.expand_dims(y1,1)\n",
    "        #y2=tf.expand_dims(y2,1)\n",
    "        #y3=tf.expand_dims(y3,1)\n",
    "        #y4=tf.expand_dims(y4,1)\n",
    "\n",
    "        x=tf.concat([x1,x2,x3,x4], 1)\n",
    "        y=tf.concat([y1,y2,y3,y4], 1)\n",
    "\n",
    "        yield x,y #Yield all images and their mutual label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T04:22:43.578606Z",
     "iopub.status.busy": "2022-12-02T04:22:43.578235Z",
     "iopub.status.idle": "2022-12-02T04:22:43.589052Z",
     "shell.execute_reply": "2022-12-02T04:22:43.587984Z",
     "shell.execute_reply.started": "2022-12-02T04:22:43.578574Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def multiple_image_data_generator2(generator,directory, batch_size, img_height,img_width):\n",
    "    \n",
    "    generator_X = generator.flow_from_directory(directory,\n",
    "                                          target_size = (img_width, img_height),\n",
    "                                          class_mode = 'categorical',\n",
    "                                          batch_size = batch_size,\n",
    "                                          shuffle=False)\n",
    "    \n",
    "   \n",
    "    x1,y1 = (generator_X[0])\n",
    "    x1=tf.expand_dims(x1,1)\n",
    "    \n",
    "    global viewCount\n",
    "    \n",
    "    \n",
    "    if(viewCount == 0):\n",
    "        while True:\n",
    "            #x=\n",
    "            \n",
    "            x2,y2 = (generator_X.next())\n",
    "            x3,y3 = (generator_X.next())\n",
    "            x4,y4 = (generator_X.next())\n",
    "            \n",
    "            x2=tf.expand_dims(x2,1)\n",
    "            x3=tf.expand_dims(x3,1)\n",
    "            x4=tf.expand_dims(x4,1)\n",
    "            #y1=tf.expand_dims(y1,1)\n",
    "            #y2=tf.expand_dims(y2,1)\n",
    "            #y3=tf.expand_dims(y3,1)\n",
    "            #y4=tf.expand_dims(y4,1)\n",
    "\n",
    "    global x_cat, y_cat\n",
    "    x_cat=tf.concat([x1,x2,x3,x4], 1)\n",
    "    y_cat=tf.concat([y1,y2,y3,y4], 1)\n",
    "\n",
    "\n",
    "    viewCount=viewCount + 1\n",
    "    \n",
    "    yield x1,y1 #Yield just the first image and its mutual label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T04:22:43.797514Z",
     "iopub.status.busy": "2022-12-02T04:22:43.797185Z",
     "iopub.status.idle": "2022-12-02T04:22:43.804386Z",
     "shell.execute_reply": "2022-12-02T04:22:43.803234Z",
     "shell.execute_reply.started": "2022-12-02T04:22:43.797485Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "     shear_range=0.4,\n",
    "     zoom_range=0.4,\n",
    "     rotation_range=0.4,\n",
    "     width_shift_range=0.4,\n",
    "     height_shift_range=0.4,\n",
    "     horizontal_flip=True,\n",
    "     vertical_flip=True,\n",
    "    \n",
    "     fill_mode=\"nearest\"\n",
    ")\n",
    "# C:/Datasets/Miniddsm-53gb/archive/\n",
    "# C:/Code/Cross-view-attention/cross-view-attention/\n",
    "val_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255)\n",
    "#C:/Code/Cross-view-attention/cross-view-attention\n",
    "train_generator = multiple_image_data_generator(train_datagen,\n",
    "                                                'C:/Datasets/Miniddsm-53gb/archive/MINI-DDSM-Complete-JPEG-8',\n",
    "                                                4, height, width)\n",
    "val_generator = multiple_image_data_generator(val_datagen,\n",
    "                                                'C:/Datasets/Miniddsm-53gb/archive/MINI-DDSM-Complete-JPEG-8-valid',\n",
    "                                                4, height, width)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T04:22:36.111881Z",
     "iopub.status.busy": "2022-12-02T04:22:36.111501Z",
     "iopub.status.idle": "2022-12-02T04:22:36.326605Z",
     "shell.execute_reply": "2022-12-02T04:22:36.325541Z",
     "shell.execute_reply.started": "2022-12-02T04:22:36.111830Z"
    }
   },
   "outputs": [],
   "source": [
    "x,y=next(val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T04:22:37.187857Z",
     "iopub.status.busy": "2022-12-02T04:22:37.186960Z",
     "iopub.status.idle": "2022-12-02T04:22:37.197148Z",
     "shell.execute_reply": "2022-12-02T04:22:37.196011Z",
     "shell.execute_reply.started": "2022-12-02T04:22:37.187794Z"
    }
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T04:22:39.637320Z",
     "iopub.status.busy": "2022-12-02T04:22:39.636947Z",
     "iopub.status.idle": "2022-12-02T04:22:39.877705Z",
     "shell.execute_reply": "2022-12-02T04:22:39.876691Z",
     "shell.execute_reply.started": "2022-12-02T04:22:39.637288Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(x[0,2,:,:,:])\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'C:/Users/marcb/Downloads/miniddsm2/MINI-DDSM-Complete-JPEG-8-valid',\n",
    "# val_datagen = ImageDataGenerator(rescale=1. / 255) \t\n",
    "\n",
    "# valid_generator =multiple_image_data_generator(val_datagen,\n",
    "#                                                 'D:/Datasets/Breast/Miniddsm-53gb/archive/MINI-DDSM-Complete-JPEG-8-valid',\n",
    "#                                                  4, height, width)\n",
    "#valid_generator =single_image_data_generator(val_datagen,\n",
    "#                                                'D:/Datasets/Breast/Miniddsm-53gb/archive/MINI-DDSM-Complete-JPEG-8-valid',\n",
    "#                                                 4, height, width)\n",
    "# valid_generator = val_datagen.flow_from_directory(\n",
    "#     'D:/Datasets/Breast/Miniddsm-53gb/archive/MINI-DDSM-Complete-JPEG-8-valid',\n",
    "#     target_size=(600,300), \n",
    "#     interpolation=\"lanczos\",\n",
    "#     color_mode='rgb', \n",
    "#     batch_size=4, \n",
    "#     class_mode='categorical', \n",
    "#     shuffle=True)\n",
    "    \n",
    "\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "#model.add()\n",
    "#model.add(Flatten())\n",
    "#model.add(Dense(256,activation='PReLU'))\n",
    "#model.add(Dropout(.5))\n",
    "#model.add(BatchNormalization())\n",
    "#model.add(Dense(256,activation='PReLU'))\n",
    "#model.add(Dropout(.5))\n",
    "#model.add(BatchNormalization())\n",
    "#model.add(Dense(128,activation='PReLU'))\n",
    "#model.add(Dropout(.5))\n",
    "#model.add(BatchNormalization())\n",
    "\n",
    "#model.add(Dense(3,activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "def auc_score(y_true, y_pred):\n",
    "    if len(np.unique(y_true[:,1])) == 1:\n",
    "        return 0.5\n",
    "    else:\n",
    "        return roc_auc_score(y_true, y_pred)\n",
    "def auc(y_true, y_pred):\n",
    "    return tf.numpy_function(auc_score, (y_true, y_pred), tf.double)\n",
    "#in model.compile you can use auc function name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T04:18:51.696365Z",
     "iopub.status.busy": "2022-12-02T04:18:51.695862Z",
     "iopub.status.idle": "2022-12-02T04:18:51.709818Z",
     "shell.execute_reply": "2022-12-02T04:18:51.708949Z",
     "shell.execute_reply.started": "2022-12-02T04:18:51.696325Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size=4\n",
    "n_train=6588\n",
    "n_test=879\n",
    "n_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T04:22:52.560770Z",
     "iopub.status.busy": "2022-12-02T04:22:52.560407Z",
     "iopub.status.idle": "2022-12-02T04:35:49.521355Z",
     "shell.execute_reply": "2022-12-02T04:35:49.519716Z",
     "shell.execute_reply.started": "2022-12-02T04:22:52.560739Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import metrics\n",
    "\n",
    "base_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-2),loss='categorical_crossentropy', \n",
    "              metrics=[\n",
    "                          'categorical_accuracy', 'AUC'\n",
    "                      ])\n",
    "#steps_per_epoch=round(n_train /(4*batch_size)),\n",
    "base_model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=round(6112 /10),\n",
    "        epochs=60,\n",
    "        validation_data=val_generator,\n",
    "        validation_steps=round(1785 /10))\n",
    "        #validation_steps=round(n_test /(4*batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")\n",
    "\n",
    "#test_generator = multiple_image_data_generator(test_datagen,\n",
    "#                                                'C:/Code/Cross-view-attention/cross-view-attention/MINI-DDSM-Complete-JPEG-8-test',\n",
    "#                                                4, height, width)\n",
    "                                                \n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    'C:/Datasets/Miniddsm-53gb/archive/MINI-DDSM-Complete-JPEG-8-test',\n",
    "    target_size=(600,300), \n",
    "    interpolation=\"lanczos\",\n",
    "    color_mode='rgb', \n",
    "    batch_size=4, \n",
    "    class_mode='categorical', \n",
    "    shuffle=True)\n",
    "\n",
    "#y_pred=model.predict_on_batch(test_datagen)\n",
    "test_evaluation = base_model.evaluate(test_generator,verbose = 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(base_model.metrics_names)):\n",
    "    print(\"%s%s: %.2f%%\" % (\" \",base_model.metrics_names[i], test_evaluation[i]*100))\n",
    "\n",
    "\n",
    "#print(\"Final Model Accuracy = \", (test_acc))\n",
    "#print('Accuracy:', test_evaluation.accuracy_score())\n",
    "#print('Precision:', test_evaluation.precision_score())\n",
    "#print('Recall:', np.round(metrics.recall_score(y_test[:,0],y_pred, average='weighted'),5))\n",
    "#print('F1 Score:', np.round(metrics.f1_score(y_test[:,0], y_pred, average='weighted'),5))\n",
    "#print('ROC AUC Score:', np.round(metrics.roc_auc_score(y_test[:,0], y_pred,multi_class='ovo', average='weighted'),5))\n",
    "#print('Cohen Kappa Score:', np.round(metrics.cohen_kappa_score(y_test[:,0], y_pred),5))\n",
    "#print('\\t\\tClassification Report:\\n', metrics.classification_report(y_test[:,0], y_pred,target_names=target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
