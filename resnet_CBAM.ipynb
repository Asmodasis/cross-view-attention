{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All modules have been imported\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#import cv2\n",
    "#import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "#import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import scipy\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.losses import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras.preprocessing.image import *\n",
    "from tensorflow.keras.utils import *\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import *\n",
    "import tensorflow.keras.backend as K\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from colorama import Fore\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from skimage.io import *\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from keras.layers import Input\n",
    "from keras import layers\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import GlobalMaxPooling2D\n",
    "from keras.layers import ZeroPadding2D\n",
    "from keras.layers import AveragePooling2D\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Softmax\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing import image\n",
    "import keras.backend as K\n",
    "import keras_applications\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import decode_predictions\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras_applications.imagenet_utils import _obtain_input_shape\n",
    "from keras.utils.layer_utils import get_source_inputs\n",
    "print(\"All modules have been imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_percent = 100 # percent of original size\n",
    "width = int(np.round(600 * scale_percent / 100))\n",
    "height = int(np.round(300 * scale_percent / 100))\n",
    "dim = (width, height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###############################<br>\n",
    "# ResNet50 Model Definition ###<br>\n",
    "###############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels.h5'\n",
    "WEIGHTS_PATH_NO_TOP = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(input_tensor, kernel_size, filters, stage, block):\n",
    "    \"\"\"The identity block is the block that has no conv layer at shortcut.\n",
    "    # Arguments\n",
    "        input_tensor: input tensor\n",
    "        kernel_size: defualt 3, the kernel size of middle conv layer at main path\n",
    "        filters: list of integers, the filterss of 3 conv layer at main path\n",
    "        stage: integer, current stage label, used for generating layer names\n",
    "        block: 'a','b'..., current block label, used for generating layer names\n",
    "    # Returns\n",
    "        Output tensor for the block.\n",
    "    \"\"\"\n",
    "    filters1, filters2, filters3 = filters\n",
    "    if K.image_data_format() == 'channels_last':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    x = Conv2D(filters1, (1, 1), name=conv_name_base + '2a')(input_tensor)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(filters2, kernel_size,\n",
    "               padding='same', name=conv_name_base + '2b')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(filters3, (1, 1), name=conv_name_base + '2c')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
    "    x = layers.add([x, input_tensor])\n",
    "    x = Activation('relu')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(input_tensor, kernel_size, filters, stage, block, strides=(2, 2)):\n",
    "    \"\"\"conv_block is the block that has a conv layer at shortcut\n",
    "    # Arguments\n",
    "        input_tensor: input tensor\n",
    "        kernel_size: defualt 3, the kernel size of middle conv layer at main path\n",
    "        filters: list of integers, the filterss of 3 conv layer at main path\n",
    "        stage: integer, current stage label, used for generating layer names\n",
    "        block: 'a','b'..., current block label, used for generating layer names\n",
    "    # Returns\n",
    "        Output tensor for the block.\n",
    "    Note that from stage 3, the first conv layer at main path is with strides=(2,2)\n",
    "    And the shortcut should have strides=(2,2) as well\n",
    "    \"\"\"\n",
    "    filters1, filters2, filters3 = filters\n",
    "    if K.image_data_format() == 'channels_last':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    x = Conv2D(filters1, (1, 1), strides=strides,\n",
    "               name=conv_name_base + '2a')(input_tensor)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(filters2, kernel_size, padding='same',\n",
    "               name=conv_name_base + '2b')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(filters3, (1, 1), name=conv_name_base + '2c')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
    "    shortcut = Conv2D(filters3, (1, 1), strides=strides,\n",
    "                      name=conv_name_base + '1')(input_tensor)\n",
    "    shortcut = BatchNormalization(axis=bn_axis, name=bn_name_base + '1')(shortcut)\n",
    "    x = layers.add([x, shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cbam_block(cbam_feature, ratio=8):\n",
    "\t\"\"\"Contains the implementation of Convolutional Block Attention Module(CBAM) block.\n",
    "\tAs described in https://arxiv.org/abs/1807.06521.\n",
    "\t\"\"\"\n",
    "\t\n",
    "\tcbam_feature = channel_attention(cbam_feature, ratio)\n",
    "\tcbam_feature = spatial_attention(cbam_feature)\n",
    "\treturn cbam_feature\n",
    "\n",
    "def channel_attention(input_feature, ratio=8):\n",
    "\tchannel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
    "\tchannel = input_feature.shape[channel_axis]\t\n",
    "\t#channel = input_feature.shape\n",
    "\tshared_layer_one = Dense(channel//ratio,\n",
    "\t\t\t\t\t\t\t activation='relu',\n",
    "\t\t\t\t\t\t\t kernel_initializer='he_normal',\n",
    "\t\t\t\t\t\t\t use_bias=True,\n",
    "\t\t\t\t\t\t\t bias_initializer='zeros')\n",
    "\tshared_layer_two = Dense(channel,\n",
    "\t\t\t\t\t\t\t kernel_initializer='he_normal',\n",
    "\t\t\t\t\t\t\t use_bias=True,\n",
    "\t\t\t\t\t\t\t bias_initializer='zeros')\n",
    "\t\n",
    "\tavg_pool = GlobalAveragePooling2D()(input_feature)    \n",
    "\tavg_pool = Reshape((1,1,channel))(avg_pool)\n",
    "\tassert avg_pool.shape[1:] == (1,1,channel)\n",
    "\tavg_pool = shared_layer_one(avg_pool)\n",
    "\tassert avg_pool.shape[1:] == (1,1,channel//ratio)\n",
    "\tavg_pool = shared_layer_two(avg_pool)\n",
    "\tassert avg_pool.shape[1:] == (1,1,channel)\n",
    "\t\n",
    "\tmax_pool = GlobalMaxPooling2D()(input_feature)\n",
    "\tmax_pool = Reshape((1,1,channel))(max_pool)\n",
    "\tassert max_pool.shape[1:] == (1,1,channel)\n",
    "\tmax_pool = shared_layer_one(max_pool)\n",
    "\tassert max_pool.shape[1:] == (1,1,channel//ratio)\n",
    "\tmax_pool = shared_layer_two(max_pool)\n",
    "\tassert max_pool.shape[1:] == (1,1,channel)\n",
    "\t\n",
    "\tcbam_feature = Add()([avg_pool,max_pool])\n",
    "\tcbam_feature = Activation('sigmoid')(cbam_feature)\n",
    "\tprint (channel)\n",
    "\tif K.image_data_format() == \"channels_first\":\n",
    "\t\tcbam_feature = Permute((3, 1, 2))(cbam_feature)\n",
    "\t\n",
    "\treturn multiply([input_feature, cbam_feature])\n",
    "\n",
    "def spatial_attention(input_feature):\n",
    "\tkernel_size = 7\n",
    "\t\n",
    "\tif K.image_data_format() == \"channels_first\":\n",
    "\t\tchannel = input_feature.shape[1]\n",
    "\t\tcbam_feature = Permute((2,3,1))(input_feature)\n",
    "\telse:\n",
    "\t\tchannel = input_feature.shape[-1]\n",
    "\t\tcbam_feature = input_feature\n",
    "\t\n",
    "\tavg_pool = Lambda(lambda x: K.mean(x, axis=3, keepdims=True))(cbam_feature)\n",
    "\tassert avg_pool.shape[-1] == 1\n",
    "\tmax_pool = Lambda(lambda x: K.max(x, axis=3, keepdims=True))(cbam_feature)\n",
    "\tassert max_pool.shape[-1] == 1\n",
    "\tconcat = Concatenate(axis=3)([avg_pool, max_pool])\n",
    "\tassert concat.shape[-1] == 2\n",
    "\tcbam_feature = Conv2D(filters = 1,\n",
    "\t\t\t\t\tkernel_size=kernel_size,\n",
    "\t\t\t\t\tstrides=1,\n",
    "\t\t\t\t\tpadding='same',\n",
    "\t\t\t\t\tactivation='sigmoid',\n",
    "\t\t\t\t\tkernel_initializer='he_normal',\n",
    "\t\t\t\t\tuse_bias=False)(concat)\t\n",
    "\tassert cbam_feature.shape[-1] == 1\n",
    "\t\n",
    "\tif K.image_data_format() == \"channels_first\":\n",
    "\t\tcbam_feature = Permute((3, 1, 2))(cbam_feature)\n",
    "\tprint (multiply([input_feature, cbam_feature]))\n",
    "\treturn multiply([input_feature, cbam_feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MyResNet50(dimension,include_top=True, weights='imagenet',\n",
    "             input_tensor=None, input_shape=None,\n",
    "             pooling=None,\n",
    "             classes=1):\n",
    "    \"\"\"Instantiates the ResNet50 architecture.\n",
    "    Optionally loads weights pre-trained\n",
    "    on ImageNet. Note that when using TensorFlow,\n",
    "    for best performance you should set\n",
    "    `image_data_format=\"channels_last\"` in your Keras config\n",
    "    at ~/.keras/keras.json.\n",
    "    The model and the weights are compatible with both\n",
    "    TensorFlow and Theano. The data format\n",
    "    convention used by the model is the one\n",
    "    specified in your Keras config file.\n",
    "    # Arguments\n",
    "        include_top: whether to include the fully-connected\n",
    "            layer at the top of the network.\n",
    "        weights: one of `None` (random initialization)\n",
    "            or \"imagenet\" (pre-training on ImageNet).\n",
    "        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n",
    "            to use as image input for the model.\n",
    "        input_shape: optional shape tuple, only to be specified\n",
    "            if `include_top` is False (otherwise the input shape\n",
    "            has to be `(224, 224, 3)` (with `channels_last` data format)\n",
    "            or `(3, 224, 244)` (with `channels_first` data format).\n",
    "            It should have exactly 3 inputs channels,\n",
    "            and width and height should be no smaller than 197.\n",
    "            E.g. `(200, 200, 3)` would be one valid value.\n",
    "        pooling: Optional pooling mode for feature extraction\n",
    "            when `include_top` is `False`.\n",
    "            - `None` means that the output of the model will be\n",
    "                the 4D tensor output of the\n",
    "                last convolutional layer.\n",
    "            - `avg` means that global average pooling\n",
    "                will be applied to the output of the\n",
    "                last convolutional layer, and thus\n",
    "                the output of the model will be a 2D tensor.\n",
    "            - `max` means that global max pooling will\n",
    "                be applied.\n",
    "        classes: optional number of classes to classify images\n",
    "            into, only to be specified if `include_top` is True, and\n",
    "            if no `weights` argument is specified.\n",
    "    # Returns\n",
    "        A Keras model instance.\n",
    "    # Raises\n",
    "        ValueError: in case of invalid argument for `weights`,\n",
    "            or invalid input shape.\n",
    "    \"\"\"\n",
    "    if weights not in {'imagenet', None}:\n",
    "        raise ValueError('The `weights` argument should be either '\n",
    "                         '`None` (random initialization) or `imagenet` '\n",
    "                         '(pre-training on ImageNet).')\n",
    "    if weights == 'imagenet' and include_top and classes != 1000:\n",
    "        raise ValueError('If using `weights` as imagenet with `include_top`'\n",
    "                         ' as true, `classes` should be 1000')\n",
    "    #######################################\n",
    "    ##### Determine proper input shape ####\n",
    "    #######################################\n",
    "    input_shape = [dimension[1],dimension[0],3]\n",
    "    #print (input_tensor)\n",
    "    if input_tensor is None:\n",
    "        img_input = Input(shape=input_shape)\n",
    "    else:\n",
    "        if not K.is_keras_tensor(input_tensor):\n",
    "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "    if K.image_data_format() == 'channels_last':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "    \n",
    "    #print ('before',img_input)\n",
    "    #input_tensor=input_tensor[:,:,:,:,0]\n",
    "    #x=np.zeros([2,dimension[1],dimension[0],3])\n",
    "    x=img_input\n",
    "    #x=tf.expand_dims(x, axis=3)\n",
    "    print (x.shape)\n",
    "   # x1=img_input[:,:,:,:,1]\n",
    "   # x2=img_input[:,:,:,:,2]\n",
    "    #x3=img_input[:,:,:,:,3]\n",
    "\n",
    "    #print ('after',x)\n",
    "    x = ZeroPadding2D((3, 3))(x)\n",
    "   # x1 = ZeroPadding2D((3, 3))(x1)\n",
    "   # x2 = ZeroPadding2D((3, 3))(x2)\n",
    "    #x3 = ZeroPadding2D((3, 3))(x3)\n",
    "    #print ('first', x)\n",
    "    x = Conv2D(64, (7, 7), strides=(2, 2), name='conv1')(x)\n",
    "    #x1 = Conv2D(64, (7, 7), strides=(2, 2), name='conv1_1')(x1)\n",
    "    #x2 = Conv2D(64, (7, 7), strides=(2, 2), name='conv1_2')(x2)\n",
    "    #x3 = Conv2D(64, (7, 7), strides=(2, 2), name='conv1_3')(x3)\n",
    "    x = BatchNormalization(axis=bn_axis, name='bn_conv1')(x)\n",
    "    #x1 = BatchNormalization(axis=bn_axis, name='bn_conv1_1')(x1)\n",
    "    #x2 = BatchNormalization(axis=bn_axis, name='bn_conv1_2')(x2)\n",
    "    #x3 = BatchNormalization(axis=bn_axis, name='bn_conv1_3')(x3)\n",
    "    x = Activation('relu')(x)\n",
    "    #x1 = Activation('relu')(x1)\n",
    "    #x2 = Activation('relu')(x2)\n",
    "    #x3 = Activation('relu')(x3)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "    #x1 = MaxPooling2D((3, 3), strides=(2, 2))(x1)\n",
    "    #x2 = MaxPooling2D((3, 3), strides=(2, 2))(x2)\n",
    "    #x3 = MaxPooling2D((3, 3), strides=(2, 2))(x3)\n",
    "    x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))\n",
    "    #x1 = conv_block(x1, 3, [64, 64, 256], stage=2, block='a1', strides=(1, 1))\n",
    "    #x2 = conv_block(x2, 3, [64, 64, 256], stage=2, block='a2', strides=(1, 1))\n",
    "    #x3 = conv_block(x3, 3, [64, 64, 256], stage=2, block='a3', strides=(1, 1))\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='b')\n",
    "    #x1 = identity_block(x1, 3, [64, 64, 256], stage=2, block='b1')\n",
    "    #x2 = identity_block(x2, 3, [64, 64, 256], stage=2, block='b2')\n",
    "    #x3 = identity_block(x3, 3, [64, 64, 256], stage=2, block='b3')\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='c')\n",
    "    #x1 = identity_block(x1, 3, [64, 64, 256], stage=2, block='c1')\n",
    "    #x2 = identity_block(x2, 3, [64, 64, 256], stage=2, block='c2')\n",
    "    #x3 = identity_block(x3, 3, [64, 64, 256], stage=2, block='c3')\n",
    "    #print ('x1',x1.shape[3])\n",
    "    \n",
    "    x = cbam_block(x)\n",
    "    x = conv_block(x, 3, [128, 128, 512], stage=3, block='a')\n",
    "   # x1 = conv_block(x1, 3, [128, 128, 512], stage=3, block='a1')\n",
    "   # x2 = conv_block(x2, 3, [128, 128, 512], stage=3, block='a2')\n",
    "    #x3 = conv_block(x2, 3, [128, 128, 512], stage=3, block='a3')\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='b')\n",
    "    #x1 = identity_block(x1, 3, [128, 128, 512], stage=3, block='b1')\n",
    "    #x2 = identity_block(x2, 3, [128, 128, 512], stage=3, block='b2')\n",
    "    #x3 = identity_block(x3, 3, [128, 128, 512], stage=3, block='b3')\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='c')\n",
    "   # x1 = identity_block(x1, 3, [128, 128, 512], stage=3, block='c1')\n",
    "   # x2 = identity_block(x2, 3, [128, 128, 512], stage=3, block='c2')\n",
    "    #x3 = identity_block(x3, 3, [128, 128, 512], stage=3, block='c3')\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='d')\n",
    "    #x1 = identity_block(x1, 3, [128, 128, 512], stage=3, block='d1')\n",
    "    #x2 = identity_block(x2, 3, [128, 128, 512], stage=3, block='d2')\n",
    "    #x3 = identity_block(x3, 3, [128, 128, 512], stage=3, block='d3')\n",
    "\n",
    "    x = cbam_block(x)\n",
    "       # x = cvam_block(x,x1,x2)\n",
    "    #x1 = cvam_block(x1,x,x3)\n",
    "    # x2 = cvam_block(x2,x3,x)\n",
    "    # x3 = cvam_block(x3,x2,x1)\n",
    "    x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a')\n",
    "    #x1 = conv_block(x1, 3, [256, 256, 1024], stage=4, block='a1')\n",
    "    #x2 = conv_block(x2, 3, [256, 256, 1024], stage=4, block='a2')\n",
    "    #x3 = conv_block(x3, 3, [256, 256, 1024], stage=4, block='a3')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b')\n",
    "    #x1 = identity_block(x1, 3, [256, 256, 1024], stage=4, block='b1')\n",
    "    #x2 = identity_block(x2, 3, [256, 256, 1024], stage=4, block='b2')\n",
    "    #x3 = identity_block(x3, 3, [256, 256, 1024], stage=4, block='b3')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='c')\n",
    "    #x1 = identity_block(x1, 3, [256, 256, 1024], stage=4, block='c1')\n",
    "    #x2 = identity_block(x2, 3, [256, 256, 1024], stage=4, block='c2')\n",
    "    #x3 = identity_block(x3, 3, [256, 256, 1024], stage=4, block='c3')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='d')\n",
    "    #x1 = identity_block(x1, 3, [256, 256, 1024], stage=4, block='d1')\n",
    "    #x2 = identity_block(x2, 3, [256, 256, 1024], stage=4, block='d2')\n",
    "    #x3 = identity_block(x3, 3, [256, 256, 1024], stage=4, block='d3')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='e')\n",
    "    #x1 = identity_block(x1, 3, [256, 256, 1024], stage=4, block='e1')\n",
    "    #x2 = identity_block(x2, 3, [256, 256, 1024], stage=4, block='e2')\n",
    "    #x3 = identity_block(x3, 3, [256, 256, 1024], stage=4, block='e3')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='f')\n",
    "    #x1 = identity_block(x1, 3, [256, 256, 1024], stage=4, block='f1')\n",
    "    #x2 = identity_block(x2, 3, [256, 256, 1024], stage=4, block='f2')\n",
    "    #x3 = identity_block(x3, 3, [256, 256, 1024], stage=4, block='f3')\n",
    "\n",
    "    x = cbam_block(x)\n",
    "    #x = cvam_block(x,x1,x2)\n",
    "#     x1 = cvam_block(x1,x,x3)\n",
    "#     x2 = cvam_block(x2,x3,x)\n",
    "    # x3 = cvam_block(x3,x2,x1)\n",
    "    x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a')\n",
    "    #x1 = conv_block(x1, 3, [512, 512, 2048], stage=5, block='a1')\n",
    "    #x2 = conv_block(x2, 3, [512, 512, 2048], stage=5, block='a2')\n",
    "    #x3 = conv_block(x3, 3, [512, 512, 2048], stage=5, block='a3')\n",
    "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b')\n",
    "    #x1 = identity_block(x1, 3, [512, 512, 2048], stage=5, block='b1')\n",
    "    #x2 = identity_block(x2, 3, [512, 512, 2048], stage=5, block='b2')\n",
    "    #x3 = identity_block(x3, 3, [512, 512, 2048], stage=5, block='b3')\n",
    "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c')\n",
    "    #x1 = identity_block(x1, 3, [512, 512, 2048], stage=5, block='c1')\n",
    "    #x2 = identity_block(x2, 3, [512, 512, 2048], stage=5, block='c2')\n",
    "    #x3 = identity_block(x3, 3, [512, 512, 2048], stage=5, block='c3')\n",
    "\n",
    "    x = cbam_block(x)\n",
    "    #x = cvam_block(x,x1,x2)\n",
    "    #x1 = cvam_block(x1,x,x3)\n",
    "    # x2 = cvam_block(x2,x3,x)\n",
    "    # x3 = cvam_block(x3,x2,x1)\n",
    "\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "        # Ensure that the model takes into account\n",
    "    # any potential predecessors of `input_tensor`.\n",
    "    print (input_tensor, img_input)\n",
    "    if input_tensor is not None:\n",
    "        inputs = get_source_inputs(input_tensor)\n",
    "    else:\n",
    "        inputs = img_input\n",
    "    # Create model.\n",
    "    model = Model(inputs=inputs, outputs=x, name='resnet50')\n",
    "\n",
    "    # load weights\n",
    "    if weights == 'imagenet':\n",
    "        if include_top:\n",
    "            weights_path = get_file('resnet50_weights_tf_dim_ordering_tf_kernels.h5',\n",
    "                                    WEIGHTS_PATH,\n",
    "                                    cache_subdir='models',\n",
    "                                    md5_hash='a7b3fe01876f51b976af0dea6bc144eb')\n",
    "        else:\n",
    "            weights_path = get_file('resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "                                    WEIGHTS_PATH_NO_TOP,\n",
    "                                    cache_subdir='models',\n",
    "                                    md5_hash='a268eb855778b3df3c7506639542a6af')\n",
    "        model.load_weights(weights_path, by_name = True, skip_mismatch = True)\n",
    "        if K.backend() == 'theano':\n",
    "            layer_utils.convert_all_kernels_in_model(model)\n",
    "        if K.image_data_format() == 'channels_first':\n",
    "            if include_top:\n",
    "                maxpool = model.get_layer(name='avg_pool')\n",
    "                shape = maxpool.output_shape[1:]\n",
    "                dense = model.get_layer(name='fc1000')\n",
    "                layer_utils.convert_dense_weights_data_format(dense, shape, 'channels_first')\n",
    "            if K.backend() == 'tensorflow':\n",
    "                warnings.warn('You are using the TensorFlow backend, yet you ')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 300, 600, 3)\n",
      "256\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 74, 149, 256), dtype=tf.float32, name=None), name='multiply_1/mul:0', description=\"created by layer 'multiply_1'\")\n",
      "512\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 37, 75, 512), dtype=tf.float32, name=None), name='multiply_4/mul:0', description=\"created by layer 'multiply_4'\")\n",
      "1024\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 19, 38, 1024), dtype=tf.float32, name=None), name='multiply_7/mul:0', description=\"created by layer 'multiply_7'\")\n",
      "2048\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 10, 19, 2048), dtype=tf.float32, name=None), name='multiply_10/mul:0', description=\"created by layer 'multiply_10'\")\n",
      "None KerasTensor(type_spec=TensorSpec(shape=(None, 300, 600, 3), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\")\n",
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 300, 600, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d (ZeroPadding2D)  (None, 306, 606, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 150, 300, 64) 9472        zero_padding2d[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 150, 300, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 150, 300, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 74, 149, 64)  0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 74, 149, 64)  4160        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 74, 149, 64)  256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 74, 149, 64)  0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 74, 149, 64)  36928       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 74, 149, 64)  256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 74, 149, 64)  0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 74, 149, 256) 16640       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 74, 149, 256) 16640       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 74, 149, 256) 1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 74, 149, 256) 1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 74, 149, 256) 0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 74, 149, 256) 0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 74, 149, 64)  16448       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 74, 149, 64)  256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 74, 149, 64)  0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 74, 149, 64)  36928       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 74, 149, 64)  256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 74, 149, 64)  0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 74, 149, 256) 16640       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 74, 149, 256) 1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 74, 149, 256) 0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 74, 149, 256) 0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 74, 149, 64)  16448       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 74, 149, 64)  256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 74, 149, 64)  0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 74, 149, 64)  36928       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 74, 149, 64)  256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 74, 149, 64)  0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 74, 149, 256) 16640       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 74, 149, 256) 1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 74, 149, 256) 0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 74, 149, 256) 0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 256)          0           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d (GlobalMax (None, 256)          0           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 1, 1, 256)    0           global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 1, 1, 256)    0           global_max_pooling2d[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1, 1, 32)     8224        reshape[0][0]                    \n",
      "                                                                 reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1, 1, 256)    8448        dense[0][0]                      \n",
      "                                                                 dense[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 1, 1, 256)    0           dense_1[0][0]                    \n",
      "                                                                 dense_1[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 1, 1, 256)    0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, 74, 149, 256) 0           activation_9[0][0]               \n",
      "                                                                 activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 74, 149, 1)   0           multiply[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 74, 149, 1)   0           multiply[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 74, 149, 2)   0           lambda[0][0]                     \n",
      "                                                                 lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 74, 149, 1)   98          concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, 74, 149, 256) 0           multiply[0][0]                   \n",
      "                                                                 conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 37, 75, 128)  32896       multiply_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 37, 75, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 37, 75, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 37, 75, 128)  147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 37, 75, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 37, 75, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 37, 75, 512)  66048       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 37, 75, 512)  131584      multiply_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 37, 75, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 37, 75, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 37, 75, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 37, 75, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 37, 75, 128)  65664       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 37, 75, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 37, 75, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 37, 75, 128)  147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 37, 75, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 37, 75, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 37, 75, 512)  66048       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 37, 75, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 37, 75, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 37, 75, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 37, 75, 128)  65664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 37, 75, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 37, 75, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 37, 75, 128)  147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 37, 75, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 37, 75, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 37, 75, 512)  66048       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 37, 75, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 37, 75, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 37, 75, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 37, 75, 128)  65664       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 37, 75, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 37, 75, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 37, 75, 128)  147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 37, 75, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 37, 75, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 37, 75, 512)  66048       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 37, 75, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 37, 75, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 37, 75, 512)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 512)          0           activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_1 (GlobalM (None, 512)          0           activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 1, 1, 512)    0           global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 1, 1, 512)    0           global_max_pooling2d_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1, 1, 64)     32832       reshape_2[0][0]                  \n",
      "                                                                 reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1, 1, 512)    33280       dense_2[0][0]                    \n",
      "                                                                 dense_2[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 1, 1, 512)    0           dense_3[0][0]                    \n",
      "                                                                 dense_3[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 1, 1, 512)    0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "multiply_3 (Multiply)           (None, 37, 75, 512)  0           activation_22[0][0]              \n",
      "                                                                 activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 37, 75, 1)    0           multiply_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 37, 75, 1)    0           multiply_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 37, 75, 2)    0           lambda_2[0][0]                   \n",
      "                                                                 lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 37, 75, 1)    98          concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_5 (Multiply)           (None, 37, 75, 512)  0           multiply_3[0][0]                 \n",
      "                                                                 conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 19, 38, 256)  131328      multiply_5[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 19, 38, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 19, 38, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 19, 38, 256)  590080      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 19, 38, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 19, 38, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 19, 38, 1024) 263168      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 19, 38, 1024) 525312      multiply_5[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 19, 38, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 19, 38, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 19, 38, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 19, 38, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 19, 38, 256)  262400      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 19, 38, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 19, 38, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 19, 38, 256)  590080      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 19, 38, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 19, 38, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 19, 38, 1024) 263168      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 19, 38, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 19, 38, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 19, 38, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 19, 38, 256)  262400      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 19, 38, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 19, 38, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 19, 38, 256)  590080      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 19, 38, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 19, 38, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 19, 38, 1024) 263168      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 19, 38, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 19, 38, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 19, 38, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 19, 38, 256)  262400      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 19, 38, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 19, 38, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 19, 38, 256)  590080      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 19, 38, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 19, 38, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 19, 38, 1024) 263168      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 19, 38, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 19, 38, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 19, 38, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 19, 38, 256)  262400      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 19, 38, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 19, 38, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 19, 38, 256)  590080      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 19, 38, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 19, 38, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 19, 38, 1024) 263168      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 19, 38, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 19, 38, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 19, 38, 1024) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 19, 38, 256)  262400      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 19, 38, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 19, 38, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 19, 38, 256)  590080      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 19, 38, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 19, 38, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 19, 38, 1024) 263168      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 19, 38, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 19, 38, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 19, 38, 1024) 0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 1024)         0           activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_2 (GlobalM (None, 1024)         0           activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 1, 1, 1024)   0           global_average_pooling2d_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 1, 1, 1024)   0           global_max_pooling2d_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1, 1, 128)    131200      reshape_4[0][0]                  \n",
      "                                                                 reshape_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1, 1, 1024)   132096      dense_4[0][0]                    \n",
      "                                                                 dense_4[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 1, 1, 1024)   0           dense_5[0][0]                    \n",
      "                                                                 dense_5[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 1, 1, 1024)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_6 (Multiply)           (None, 19, 38, 1024) 0           activation_41[0][0]              \n",
      "                                                                 activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 19, 38, 1)    0           multiply_6[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 19, 38, 1)    0           multiply_6[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 19, 38, 2)    0           lambda_4[0][0]                   \n",
      "                                                                 lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 19, 38, 1)    98          concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_8 (Multiply)           (None, 19, 38, 1024) 0           multiply_6[0][0]                 \n",
      "                                                                 conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 10, 19, 512)  524800      multiply_8[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 10, 19, 512)  2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 10, 19, 512)  0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 10, 19, 512)  2359808     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 10, 19, 512)  2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 10, 19, 512)  0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 10, 19, 2048) 1050624     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 10, 19, 2048) 2099200     multiply_8[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 10, 19, 2048) 8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 10, 19, 2048) 8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 10, 19, 2048) 0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 10, 19, 2048) 0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 10, 19, 512)  1049088     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 10, 19, 512)  2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 10, 19, 512)  0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 10, 19, 512)  2359808     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 10, 19, 512)  2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 10, 19, 512)  0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 10, 19, 2048) 1050624     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 10, 19, 2048) 8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 10, 19, 2048) 0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 10, 19, 2048) 0           add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 10, 19, 512)  1049088     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 10, 19, 512)  2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 10, 19, 512)  0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 10, 19, 512)  2359808     activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 10, 19, 512)  2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 10, 19, 512)  0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 10, 19, 2048) 1050624     activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 10, 19, 2048) 8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 10, 19, 2048) 0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 10, 19, 2048) 0           add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_3 (Glo (None, 2048)         0           activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_3 (GlobalM (None, 2048)         0           activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_6 (Reshape)             (None, 1, 1, 2048)   0           global_average_pooling2d_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "reshape_7 (Reshape)             (None, 1, 1, 2048)   0           global_max_pooling2d_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1, 1, 256)    524544      reshape_6[0][0]                  \n",
      "                                                                 reshape_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 1, 1, 2048)   526336      dense_6[0][0]                    \n",
      "                                                                 dense_6[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 1, 1, 2048)   0           dense_7[0][0]                    \n",
      "                                                                 dense_7[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 1, 1, 2048)   0           add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_9 (Multiply)           (None, 10, 19, 2048) 0           activation_51[0][0]              \n",
      "                                                                 activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 10, 19, 1)    0           multiply_9[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 10, 19, 1)    0           multiply_9[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 10, 19, 2)    0           lambda_6[0][0]                   \n",
      "                                                                 lambda_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 10, 19, 1)    98          concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_11 (Multiply)          (None, 10, 19, 2048) 0           multiply_9[0][0]                 \n",
      "                                                                 conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_4 (Glo (None, 2048)         0           multiply_11[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 24,985,064\n",
      "Trainable params: 24,931,944\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "base_model = MyResNet50(dim,weights='imagenet', include_top=False)\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###########################################<br>\n",
    "## Define Preprocessing Functions ####<br>\n",
    "###########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CropBorders(img):\n",
    "    nrows, ncols = img.shape[0],img.shape[1]\n",
    "    # Get the start and end rows and columns\n",
    "    l_crop = int(ncols * 0.01)\n",
    "    r_crop = int(ncols * (1 - 0.01))\n",
    "    u_crop = int(nrows * 0.04)\n",
    "    d_crop = int(nrows * (1 - 0.04))\n",
    "    cropped_img = img[u_crop:d_crop, l_crop:r_crop]    \n",
    "    return cropped_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OwnGlobalBinarise(img, thresh, maxval):       \n",
    "    binarised_img = np.zeros(img.shape, np.uint8)\n",
    "    binarised_img[img >= thresh] = maxval    \n",
    "    return binarised_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OpenMask(mask, ksize=(23, 23), operation=\"open\"):\n",
    "    kernel = cv2.getStructuringElement(shape=cv2.MORPH_RECT, ksize=ksize)    \n",
    "    if operation == \"open\":\n",
    "        edited_mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "    elif operation == \"close\":\n",
    "        edited_mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)    \n",
    "    # Then dilate\n",
    "    edited_mask = cv2.morphologyEx(edited_mask, cv2.MORPH_DILATE, kernel)\n",
    "    return edited_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SortContoursByArea(contours, reverse=True):   \n",
    "    '''\n",
    "    ----------\n",
    "    contours : {list}\n",
    "        The list of contours to sort.        \n",
    "    Returns\n",
    "    -------\n",
    "    sorted_contours : {list}\n",
    "        The list of contours sorted by contour area in descending\n",
    "        order.\n",
    "    bounding_boxes : {list}\n",
    "        The list of bounding boxes ordered corresponding to the\n",
    "        contours in `sorted_contours`.\n",
    "    '''   \n",
    "    # Sort contours based on contour area.\n",
    "    sorted_contours = sorted(contours, key=cv2.contourArea, reverse=True)    \n",
    "    # Construct the list of corresponding bounding boxes.\n",
    "    bounding_boxes = [cv2.boundingRect(c) for c in sorted_contours]\n",
    "    return sorted_contours, bounding_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DrawContourID(img, bounding_box, contour_id):    \n",
    "    '''\n",
    "    ----------\n",
    "    img: {numpy.ndarray}\n",
    "        The image to draw the contour on.\n",
    "    bounding_box : {tuple of int}\n",
    "        The bounding_rect of the given contour.\n",
    "    contour_id : {int or float}\n",
    "        The corresponding ID of the given `contour`.        \n",
    "    Returns\n",
    "    -------\n",
    "    img : {numpy.ndarray}\n",
    "        The image after the `contour` and its ID is drawn on.\n",
    "    ''' \n",
    "    # Center of bounding_rect.\n",
    "    x, y, w, h = bounding_box\n",
    "    center = ( ((x + w) // 2), ((y + h) // 2) )\n",
    "    # Draw the countour number on the image\n",
    "    cv2.putText(img=img,\n",
    "                text=f\"{contour_id}\",\n",
    "                org=center, # Bottom-left corner of the text string in the image.\n",
    "                fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                fontScale=10, \n",
    "                color=(255, 255, 255),\n",
    "                thickness=40)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def XLargestBlobs(mask, top_X=None):\n",
    "    \n",
    "    '''\n",
    "    ----------\n",
    "    mask : {numpy.ndarray, dtype=np.uint8}\n",
    "        The mask to get the top X largest blobs.\n",
    "    top_X : {int}\n",
    "        The top X contours to keep based on contour area\n",
    "        ranked in decesnding order.\n",
    "    Returns\n",
    "    -------\n",
    "    n_contours : {int}\n",
    "        The number of contours found in the given `mask`.\n",
    "    X_largest_blobs : {numpy.ndarray}\n",
    "        The corresponding mask of the image containing only\n",
    "        the top X largest contours in white.\n",
    "    '''        \n",
    "    # Find all contours from binarised image.\n",
    "    # Note: parts of the image that you want to get should be white.\n",
    "    contours, hierarchy = cv2.findContours(image=mask,\n",
    "                                           mode=cv2.RETR_EXTERNAL,\n",
    "                                           method=cv2.CHAIN_APPROX_NONE)   \n",
    "    n_contours = len(contours)    \n",
    "    # Only get largest blob if there is at least 1 contour.\n",
    "    if n_contours > 0:        \n",
    "        # Make sure that the number of contours to keep is at most equal \n",
    "        # to the number of contours present in the mask.\n",
    "        if n_contours < top_X or top_X == None:\n",
    "            top_X = n_contours        \n",
    "        # Sort contours based on contour area.\n",
    "        sorted_contours, bounding_boxes = SortContoursByArea(contours=contours,\n",
    "                                                             reverse=True)        \n",
    "        # Get the top X largest contours.\n",
    "        X_largest_contours = sorted_contours[0:top_X]        \n",
    "        # Create black canvas to draw contours on.\n",
    "        to_draw_on = np.zeros(mask.shape, np.uint8)        \n",
    "        # Draw contours in X_largest_contours.\n",
    "        X_largest_blobs = cv2.drawContours(image=to_draw_on, # Draw the contours on `to_draw_on`.\n",
    "                                           contours=X_largest_contours, # List of contours to draw.\n",
    "                                           contourIdx=-1, # Draw all contours in `contours`.\n",
    "                                           color=1, # Draw the contours in white.\n",
    "                                           thickness=-1) # Thickness of the contour lines.        \n",
    "    return n_contours, X_largest_blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ApplyMask(img, mask):   \n",
    "    '''\n",
    "    ----------\n",
    "    img : {numpy.ndarray}\n",
    "        The image to mask.\n",
    "    mask : {numpy.ndarray, dtype=np.uint8}\n",
    "        The mask to apply.        \n",
    "    Returns\n",
    "    -------\n",
    "    masked_img: {numpy.ndarray}\n",
    "        The masked image.\n",
    "    '''   \n",
    "    masked_img = img.copy()\n",
    "    masked_img[mask == 0] = 0    \n",
    "    return masked_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HorizontalFlip(mask):    \n",
    "    '''\n",
    "    ----------\n",
    "    mask : {numpy.ndarray, dtype=np.uint8}\n",
    "        The corresponding mask of the CC image to flip.\n",
    "    Returns\n",
    "    -------\n",
    "    horizontal_flip : {boolean}\n",
    "        True means need to flip horizontally,\n",
    "        False means otherwise.\n",
    "    '''    \n",
    "    # Get number of rows and columns in the image.\n",
    "    nrows, ncols = mask.shape\n",
    "    x_center = ncols // 2\n",
    "    y_center = nrows // 2    \n",
    "    # Sum down each column.\n",
    "    col_sum = mask.sum(axis=0)\n",
    "    # Sum across each row.\n",
    "    row_sum = mask.sum(axis=1)    \n",
    "    left_sum = sum(col_sum[0:x_center])\n",
    "    right_sum = sum(col_sum[x_center:-1])\n",
    "    top_sum = sum(row_sum[0:y_center])\n",
    "    bottom_sum = sum(row_sum[y_center:-1])    \n",
    "    if left_sum < right_sum:\n",
    "        horizontal_flip = True\n",
    "    else:\n",
    "        horizontal_flip = False        \n",
    "    return horizontal_flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clahe(img, clip=2.0, tile=(8, 8)):   \n",
    "    '''\n",
    "    ----------\n",
    "    img : {numpy.ndarray}\n",
    "        The image to edit.\n",
    "    clip : {int or floa}\n",
    "        Threshold for contrast limiting.\n",
    "    tile : {tuple (int, int)}\n",
    "        Size of grid for histogram equalization. Input\n",
    "        image will be divided into equally sized\n",
    "        rectangular tiles. `tile` defines the number of\n",
    "        tiles in row and column.    \n",
    "    Returns\n",
    "    -------\n",
    "    clahe_img : {numpy.ndarray}\n",
    "        The edited image.\n",
    "   '''    \n",
    "    # Convert to uint8.\n",
    "    # img = skimage.img_as_ubyte(img)\n",
    "    img = cv2.normalize(\n",
    "        img,\n",
    "        None,\n",
    "        alpha=0,\n",
    "        beta=255,\n",
    "        norm_type=cv2.NORM_MINMAX,\n",
    "        dtype=cv2.CV_32F,\n",
    "    )\n",
    "    img_uint8 = img.astype(\"uint8\")\n",
    "    clahe_create = cv2.createCLAHE(clipLimit=clip, tileGridSize=tile)\n",
    "    clahe_img = clahe_create.apply(img_uint8)\n",
    "    return clahe_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(img):\n",
    "    nrows, ncols, nchannels = img.shape\n",
    "    # If padding is required...\n",
    "    if nrows != ncols:\n",
    "        # Take the longer side as the target shape.\n",
    "        if ncols < nrows:\n",
    "            target_shape = (nrows, nrows,nchannels)\n",
    "        elif nrows < ncols:\n",
    "            target_shape = (ncols, ncols,nchannels)\n",
    "        # pad.\n",
    "        padded_img = np.zeros(shape=target_shape)\n",
    "        padded_img[:nrows, :ncols, :] = img\n",
    "    # If padding is not required...\n",
    "    elif nrows == ncols:\n",
    "        # Return original image.\n",
    "        padded_img = img\n",
    "    return cv2.resize(padded_img,dim)\n",
    "\t\n",
    "#############################################\n",
    "#### Define ImageDataGenerator Functions ####\n",
    "#############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_fun(img):\n",
    "    #Combines all the transformations\n",
    "    #img = cv2.imread(filename)\n",
    "    crop_img = CropBorders(img[:,:,0])\n",
    "    norm = np.zeros((crop_img.shape[0],crop_img.shape[1]))\n",
    "    crop_img=cv2.normalize( crop_img,norm,alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "    # Changed bin_img to 0.25 from 0.15\n",
    "    bin_img = OwnGlobalBinarise(img=crop_img,thresh=0.20, maxval=1.0)\n",
    "    mask_img = OpenMask(mask=bin_img, ksize=(2, 2), operation=\"open\")\n",
    "    _, blob_img = XLargestBlobs(mask=np.array(mask_img), top_X=1)\n",
    "    processed_img = ApplyMask(img=crop_img, mask=blob_img)\n",
    "    horizontal_flip = HorizontalFlip(mask=blob_img)\n",
    "    if horizontal_flip:\n",
    "        flipped_img = np.fliplr(processed_img)\n",
    "    else:\n",
    "        flipped_img = processed_img\n",
    "    norm = np.zeros((flipped_img.shape[0],flipped_img.shape[1]))\n",
    "    norm_image = cv2.normalize(flipped_img,norm,0,255,cv2.NORM_MINMAX)\n",
    "    clahe_cv = cv2.createCLAHE(clipLimit =2.0, tileGridSize=(8,8))\n",
    "    norm_image=clahe_cv.apply(norm_image.astype(np.uint8))\n",
    "    #norm_image=cv2.normalize(norm_image,norm,alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "    norm3=np.zeros([norm_image.shape[0],norm_image.shape[1],3])\n",
    "    norm3[:,:,0]=norm_image\n",
    "    norm3[:,:,1]=norm_image\n",
    "    norm3[:,:,2]=norm_image\n",
    "    norm3=cv2.resize(norm3,(300,600))\n",
    "    return norm3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7596 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    preprocessing_function = preprocessing_fun\n",
    "    #horizontal_flip=True,\n",
    "    #vertical_flip=True,\n",
    "    #rotation_range=10,\n",
    ")\n",
    "#'C:/Users/marcb/Downloads/miniddsm2/MINI-DDSM-Complete-JPEG-8',\n",
    "\n",
    "'''\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.4,\n",
    "    zoom_range=0.4,\n",
    "    rotation_range=0.4,\n",
    "    width_shift_range=0.4,\n",
    "    height_shift_range=0.4,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode=\"nearest\"\n",
    ")\n",
    "'''\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'C:/Datasets/Miniddsm-53gb/archive/MINI-DDSM-Complete-JPEG-8',\n",
    "    target_size=(600,300), \n",
    "    interpolation=\"lanczos\",\n",
    "    color_mode='rgb', \n",
    "    batch_size=16, \n",
    "    class_mode='categorical', \n",
    "    shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1232 images belonging to 3 classes.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Functional)        (None, 2048)              24985064  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 2048)              8192      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                32800     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 25,026,171\n",
      "Trainable params: 24,968,923\n",
      "Non-trainable params: 57,248\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 'C:/Users/marcb/Downloads/miniddsm2/MINI-DDSM-Complete-JPEG-8-valid',\n",
    "val_datagen = ImageDataGenerator(rescale=1. / 255) \t\n",
    "\n",
    "valid_generator = val_datagen.flow_from_directory(\n",
    "    'C:/Datasets/Miniddsm-53gb/archive/MINI-DDSM-Complete-JPEG-8-valid',\n",
    "    target_size=(600,300), \n",
    "    interpolation=\"lanczos\",\n",
    "    color_mode='rgb', \n",
    "    batch_size=16, \n",
    "    class_mode='categorical', \n",
    "    shuffle=True)\n",
    "\n",
    "\n",
    "\t\n",
    "###Design model\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(Flatten())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(16,activation='PReLU'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(3,activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "def auc_score(y_true, y_pred):\n",
    "    if len(np.unique(y_true[:,1])) == 1:\n",
    "        return 0.5\n",
    "    else:\n",
    "        return roc_auc_score(y_true, y_pred)\n",
    "def auc(y_true, y_pred):\n",
    "    return tf.numpy_function(auc_score, (y_true, y_pred), tf.double)\n",
    "#in model.compile you can use auc function name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8800"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size=4\n",
    "n_train=8800\n",
    "n_test=879\n",
    "n_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " assertion failed: [predictions must be <= 1] [Condition x <= y did not hold element-wise:] [x (resnet50/global_average_pooling2d_4/Mean:0) = ] [[0.0516198054 1.95772679e-13 3.56544228e-06...]...] [y (Cast_5/x:0) = ] [1]\n\t [[{{node assert_less_equal/Assert/AssertGuard/else/_11/assert_less_equal/Assert/AssertGuard/Assert}}]] [Op:__inference_train_function_17590]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Input \u001b[1;32mIn [24]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m metrics\n\u001b[0;32m      3\u001b[0m base_model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-2\u001b[39m),loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m      4\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m      5\u001b[0m                           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAUC\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      6\u001b[0m                       ])\n\u001b[1;32m----> 7\u001b[0m \u001b[43mbase_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mround\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mn_train\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m60\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mround\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mn_test\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Tensorflow-GPU\\lib\\site-packages\\keras\\engine\\training.py:1184\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1177\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1178\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1179\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1180\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1181\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1182\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1183\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1184\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1185\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1186\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Tensorflow-GPU\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:885\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    882\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    884\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 885\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    887\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    888\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Tensorflow-GPU\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:950\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    946\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Fall through to cond-based initialization.\u001b[39;00m\n\u001b[0;32m    947\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    948\u001b[0m     \u001b[38;5;66;03m# Lifting succeeded, so variables are initialized and we can run the\u001b[39;00m\n\u001b[0;32m    949\u001b[0m     \u001b[38;5;66;03m# stateless function.\u001b[39;00m\n\u001b[1;32m--> 950\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    951\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    952\u001b[0m   _, _, _, filtered_flat_args \u001b[38;5;241m=\u001b[39m \\\n\u001b[0;32m    953\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn\u001b[38;5;241m.\u001b[39m_function_spec\u001b[38;5;241m.\u001b[39mcanonicalize_function_inputs(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    954\u001b[0m           \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Tensorflow-GPU\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3039\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3036\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   3037\u001b[0m   (graph_function,\n\u001b[0;32m   3038\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3039\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3040\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Tensorflow-GPU\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1963\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1959\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1960\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1961\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1962\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1963\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1964\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1965\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1966\u001b[0m     args,\n\u001b[0;32m   1967\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1968\u001b[0m     executing_eagerly)\n\u001b[0;32m   1969\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Tensorflow-GPU\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:591\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    590\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 591\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    592\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    593\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    594\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    595\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    596\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    597\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    598\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    599\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    600\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    603\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    604\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Tensorflow-GPU\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     58\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 59\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     62\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m:  assertion failed: [predictions must be <= 1] [Condition x <= y did not hold element-wise:] [x (resnet50/global_average_pooling2d_4/Mean:0) = ] [[0.0516198054 1.95772679e-13 3.56544228e-06...]...] [y (Cast_5/x:0) = ] [1]\n\t [[{{node assert_less_equal/Assert/AssertGuard/else/_11/assert_less_equal/Assert/AssertGuard/Assert}}]] [Op:__inference_train_function_17590]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import metrics\n",
    "\n",
    "base_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-2),loss='categorical_crossentropy', \n",
    "              metrics=[\n",
    "                          'categorical_accuracy', 'AUC'\n",
    "                      ])\n",
    "base_model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=round(n_train /(4*batch_size)),\n",
    "        epochs=60,\n",
    "        validation_data=valid_generator,\n",
    "        validation_steps=round(n_test /(4*batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    'C:/Datasets/Miniddsm-53gb/archive/MINI-DDSM-Complete-JPEG-8-test',\n",
    "    target_size=(600,300), \n",
    "    interpolation=\"lanczos\",\n",
    "    color_mode='rgb', \n",
    "    batch_size=16, \n",
    "    class_mode='categorical', \n",
    "    shuffle=True)\n",
    "\n",
    "#y_pred=model.predict_on_batch(test_datagen)\n",
    "test_evaluation = model.evaluate(test_generator,verbose = 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(model.metrics_names)):\n",
    "    print(\"%s%s: %.2f%%\" % (\" \",model.metrics_names[i], test_evaluation[i]*100))\n",
    "\n",
    "\n",
    "#print(\"Final Model Accuracy = \", (test_acc))\n",
    "#print('Accuracy:', test_evaluation.accuracy_score())\n",
    "#print('Precision:', test_evaluation.precision_score())\n",
    "#print('Recall:', np.round(metrics.recall_score(y_test[:,0],y_pred, average='weighted'),5))\n",
    "#print('F1 Score:', np.round(metrics.f1_score(y_test[:,0], y_pred, average='weighted'),5))\n",
    "#print('ROC AUC Score:', np.round(metrics.roc_auc_score(y_test[:,0], y_pred,multi_class='ovo', average='weighted'),5))\n",
    "#print('Cohen Kappa Score:', np.round(metrics.cohen_kappa_score(y_test[:,0], y_pred),5))\n",
    "#print('\\t\\tClassification Report:\\n', metrics.classification_report(y_test[:,0], y_pred,target_names=target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
